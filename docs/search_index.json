[
["index.html", "eBird Best Practices Workshop Welcome", " eBird Best Practices Workshop Matthew Strimas-Mackey, Alison Johnston, Wesley M. Hochachka, Viviana Ruiz-Gutierrez, Orin J. Robinson, Eliot T. Miller, Tom Auer, Steve Kelling, Daniel Fink 2020-01-16 Welcome These lessons comprise a two part workshop on best practices for using eBird data. Part I of this workshop focuses on extracting and processing eBird data with R, while Part II covers using these data to model species distributions. The workshop as a whole is typically given over two days; however, it is designed to be modular and a half-day or one-day workshop can be given based on a subset of the material. In particular, Part I and II are largely independent of each other and can be taught individually. This workshop acts as a complement to the free online book eBird Best Practices as well as an associated paper on best practices for making reliable inferences from citizen science data. The contents of this workshop are addressed in greater detail in these resources. "],
["intro.html", "Lesson 1 Introduction 1.1 Data 1.2 Format 1.3 Setup 1.4 Tidyverse", " Lesson 1 Introduction The contents of this website comprise the notes for a workshop on best practices for using eBird data. Part I of this workshop will focus on extracting and processing eBird data, while Part II will cover using these data to model species distributions. The two parts are intentionally designed to be independent, which allows you to attend Part I, Part II, or both depending on your skills, background, and interests. 1.1 Data To follow along with the lessons in this workshop download the workshop data package. This package contains a variety of datasets for Parts I and II of this workshop. Instructions for how to use each dataset will be given in the relevant lesson. 1.2 Format This format of this workshop will be loosely based on Software Carpentry, the gold standard for workshops teaching scientific computing. As much as possible, the instructor will work through the lessons in real time, entering code live, while you code-along. Interspersed with the live coding will be exercises designed to give you a chance to practice on your own. This approach, known as participatory live coding, has been shown to be a much more effective means of learning to code than using slides or a pre-written script. Another Software Carpentry technique that we’ve adopted is the use of sticky notes. You should have two sticky notes at your desk, one blue and one yellow. Throughout the workshop, if you’ve completed an exercise or have passed a checkpoint, put the blue sticky note on your laptop to indicate that you’re done. Similarly, if you’re lost, stuck, or have a problem and need help, place the yellow sticky on your laptop. In addition to the instructor, we have several helpers roaming the room helping to troubleshoot problems. The sticky notes are the most effective way of flagging a helper down. Checkpoint Let’s stop here for a quick round on introductions, let us know who you are and how you hope to use eBird data! 1.3 Setup Before we dive into writing code, let’s take a few minutes to ensure our systems are properly set up with all the correct software and R packages. Devoting some time to this up front will reduce errors and make troubleshooting easier later in the workshop. If you followed the pre-workshop setup instructions, most of this setup should already be complete; however, we include it here to ensure everyone’s on the same page. Start by opening a browser window with four tabs pointing to the following websites: The shared Google Doc for this workshop (your instructor will provide a link). This will act as a collaborative notepad, which we can use to share code and links. Make sure you can edit the document. The eBird homepage The auk website. This auk R package is used to access eBird data and we’ll be using the website to view the documentation. The online lessons for this workshop. Checkpoint Are all tabs correctly opened? Can you edit the shared notepad? Next install or update RStudio, then open it. Look at the top line of the console, which gives your R version. If you have a version older than 3.5.0, you should consider updating R. Checkpoint Is your R version at least 3.5.0? Do you need help updating R? Create a new RStudio project called ebird-best-practices. Next, install all the packages required for this workshop and Part II, by running the following code: install.packages(&quot;remotes&quot;) remotes::install_github(&quot;mstrimas/ebppackages&quot;) The auk package uses the unix command line tool AWK to access eBird data. AWK comes installed by default on Mac OS and Linux systems, but Windows users will need to install it. To do so, install the Cygwin software making sure to use the default install location. Checkpoint Is AWK installed? Run the following code to test that auk is installed correctly and AWK is working: library(auk) library(tidyverse) tf &lt;- tempfile() system.file(&quot;extdata/ebd-sample.txt&quot;, package = &quot;auk&quot;) %&gt;% auk_ebd() %&gt;% auk_species(species = c(&quot;Canada Jay&quot;, &quot;Blue Jay&quot;)) %&gt;% auk_country(country = c(&quot;US&quot;, &quot;Canada&quot;)) %&gt;% auk_bbox(bbox = c(-100, 37, -80, 52)) %&gt;% auk_date(date = c(&quot;2012-01-01&quot;, &quot;2012-12-31&quot;)) %&gt;% auk_time(start_time = c(&quot;06:00&quot;, &quot;09:00&quot;)) %&gt;% auk_duration(duration = c(0, 60)) %&gt;% auk_complete() %&gt;% auk_filter(tf) %&gt;% read_ebd() %&gt;% pull(common_name) %&gt;% message() unlink(tf) It should print Blue Jay. Checkpoint Did “Blue Jay” print without errors? If you’re running into any setup issues that can’t be resolved, use RStudio Cloud for this workshop instead. Your instructor will explain how to connect to RStudio Cloud. 1.4 Tidyverse Throughout this workshop, we’ll be using functions from the Tidyverse. This is an opinionated set of packages for working with data in R. Packages such as dplyr, ggplot2, and purrr are part of the Tidyverse. We’ll try to explain any functions as they come up; however, there’s one important operator from the Tidyverse that needs to be explained up front: the pipe operator %&gt;%. The pipe operator takes the expression to the left of it and “pipes” it into the first argument of the expression on the right. # without pipe mean(1:10) #&gt; [1] 5.5 # with pipe 1:10 %&gt;% mean() #&gt; [1] 5.5 The value of the pipe operator becomes clear when we have several operations in a row. Using the pipe makes code easier to read and reduces the need for intermediate variables. # without pipes set.seed(1) ran_norm &lt;- rnorm(10, sd = 5) ran_norm_pos &lt;- abs(ran_norm) ran_norm_sort &lt;- sort(ran_norm_pos) ran_norm_round &lt;- round(ran_norm_sort, digits = 1) ran_norm_round #&gt; [1] 0.9 1.5 1.6 2.4 2.9 3.1 3.7 4.1 4.2 8.0 # with pipes set.seed(1) rnorm(10, sd = 5) %&gt;% abs() %&gt;% sort() %&gt;% round(digits = 1) #&gt; [1] 0.9 1.5 1.6 2.4 2.9 3.1 3.7 4.1 4.2 8.0 For those that have never used the pipe, it probably looks strange, but if you stick with it, you’ll quickly come to appreciate it. Checkpoint Any questions about the pipe? Exercise Rewrite the following code using pipes: set.seed(1) round(log(runif(10, min = 0.5)), 1) Solution set.seed(1) runif(10, min = 0.5) %&gt;% log() %&gt;% round(digits = 1) #&gt; [1] -0.5 -0.4 -0.2 0.0 -0.5 -0.1 0.0 -0.2 -0.2 -0.6 "],
["ebird-intro.html", "Lesson 2 Introduction 2.1 The auk workflow", " Lesson 2 Introduction We’ll start with a short presentation giving an introduction to eBird and the motivation behind the auk R package. The presentation can be downloaded in PowerPoint or PDF format, or viewed on SpeakerDeck. 2.1 The auk workflow Extracting eBird data using auk requires proceeding through the following steps, each of which corresponds to a lesson in this document: Data access Filter Import Pre-process Produce presence-absence data After covering these fundamentals, we’ll proceed to some applications and more advanced topics, depending on time and interest: Spatiotemporal subsampling Mapping and sumarizing eBird data A variety of more advanced topics, including assigning land cover covariates to checklists, preparing data for occupancy modeling, and handling some of the file size issues that arise when working with eBird data "],
["access.html", "Lesson 3 Data Access", " Lesson 3 Data Access The complete eBird database (with the exception of sensitive species and observations that haven’t been approved) is provided via the eBird Basic Dataset (EBD), a large tab-separated text file released monthly. To access the EBD, you’ll need to create an eBird account and sign in to eBird. Once signed in, from the eBird homepage, click on the Science tab then scroll down to click on Using eBird for science in the right-hand menu. This page compiles links to a variety datasets, tools, and educational material for using eBird data to do science; it’s a great resource! Click on the “Download raw data here” link, then proceed to the eBird Basic Dataset page. If you haven’t already done so, you’ll need to submit a request to access the EBD. You can do this after the workshop if you haven’t already, we won’t need access today. From this page you can download the eBird Basic Dataset, a large tab-separated text file that contains (nearly) every eBird observation. In this file, each row corresponds to an observation of a species on a checklist. On this page, you can also download the Sampling Event Data. In this file, each row corresponds to a checklist rather than a species observation. We’ll see why this file is important later in the workshop. The EBD is huge, so don’t download these files now. Instead, we’ll be working with a small subset of the data today, which is available in the workshop data package discussed in the Introduction. This subset contains data from the Yucatan Peninsula (Guatemala, Belize, and five Mexican sates) from 2014-2015. The EBD and Sampling Event Data are in the edb/ subdirectory of the data package. These files (and the full global EBD when you download it) need to be placed in a central location on your computer. For Mac and Linux users, we suggest creating a data/ folder in your home directory, then an ebird directory within that, and placing the files there. For Windows users, in your Documents directory, create a data/ folder, then an ebird directory within that, and place the files there. Within R, the files should now be within the directory ~/data/ebird/. If you are comfortable dealing with the file paths in R, you are free to place these files anywhere you like on your file system; however, throughout this workshop we will assume the files are in ~/data/ebird/ and you will need to adjust your code accordingly if you have stored the files elsewhere. Note that when working with the full dataset, the downloaded files will be in .tar format, and you’ll need to unarchive them (this may require 7-Zip on Windows). The resulting directory will contain a file with extension .txt.gz, this file should be uncompressed to produce a text file, which you should transfer to the central data directory on your computer. The full EBD will be over 200 GB! If this is too large to fit on your computer, it can be stored on an external hard drive. We’ll also talk later in the workshop about some ways of avoiding downloading the EBD. Checkpoint Are the files downloaded and unarchived into a central location? Let’s take a look at this dataset. If we were working with the full EBD, we wouldn’t have enough memory to read in the whole file, but we can always read a small subset. Open a new R script (01_ebird-data.R) and read in the first few lines: library(auk) library(tidyverse) ebd_top &lt;- read_tsv(&quot;~/data/ebird/ebd_2014-2015_yucatan.txt&quot;, n_max = 5) View this data frame within RStudio by clicking on it in the Environment pane. Scroll over to the SAMPLING EVENT DATA column, which uniquely identifies checklists, and note the value: S17908640. With this ID we can access any non-private checklist via the website by appending it to https://ebird.org/view/checklist/. Look at the checklist online and compare it to the EBD. Notice two things that distinguish eBird data from other citizen science data: eBird collects data on the observation process, including the survey protocol used and effort information. This facilitates more robust analyses because we can account for variation in the observation process. Complete checklists enable non-detection to be inferred from the data. Without this, there’s no way to distinguish whether a species was not observed or just not reported. For these reasons, we refer to data from complete eBird checklists with effort information as semi-structured to distinguish from both most unstructured citizen science data and traditional structure scientific surveys. Exercise Take a few minutes to explore the EBD and compare it to the checklists online. Notice above that we had to reference the full path to the text files. In general, it’s best to avoid using absolute paths in R scripts because it makes them less portable–if you’re sharing the files with someone else, they’ll need to change the file paths to point to the location where they’ve stored the eBird data. The R package auk provides a solution to this, by allowing users to set an environment variable (EDB_PATH) that points to the directory containing the eBird data. To set this variable, use the function auk_set_ebd_path(). For example, if the EBD and Sampling Event Data files are in ~/data/ebird/, use: auk_set_ebd_path(&quot;~/data/ebird/&quot;) Tip You’ll need to restart R for these changes to take effect. The function auk_ebd() creates an R object referencing the EBD text file. Now that we’ve set up an EBD path, we can reference the EBD directly within auk_ebd() even though it’s not in our working directory. # the file isn&#39;t in out working directory file.exists(&quot;ebd_2014-2015_yucatan.txt&quot;) #&gt; [1] FALSE # yet auk can still find it auk_ebd(&quot;ebd_2014-2015_yucatan.txt&quot;) #&gt; Input #&gt; EBD: /Users/mes335/data/ebird/ebd_2014-2015_yucatan.txt #&gt; #&gt; Output #&gt; Filters not executed #&gt; #&gt; Filters #&gt; Species: all #&gt; Countries: all #&gt; States: all #&gt; BCRs: all #&gt; Bounding box: full extent #&gt; Date: all #&gt; Start time: all #&gt; Last edited date: all #&gt; Protocol: all #&gt; Project code: all #&gt; Duration: all #&gt; Distance travelled: all #&gt; Records with breeding codes only: no #&gt; Complete checklists only: no You should now see the EBD text file referenced as Input in this auk_ebd object. The remainder of the information printed will be the topic of the next section. Checkpoint Were you able to create an auk_ebd object referencing the EBD without specifying the full path? "],
["filter.html", "Lesson 4 Filtering 4.1 Defining filters 4.2 Execute filters", " Lesson 4 Filtering The EBD is huge, much too large to be read into R. So, if we want to work with these data, we first need to extract a small enough subset that it can be processed in R. This is the main purpose of the auk package: it uses the unix command line utility AWK to extract data from the EBD. There are three steps to this filtering process: Set up a reference to the EBD text file with auk_ebd(). Define a set of filters specifying the subset of data you want to extract. Compile those filters into an AWK script and run it to produce a text file with the desired subset of the data. Tip Filtering with auk can be fairly coarse, we just need to make the data small enough to read into R. Once the data are in R, they can further filtering can be used to refine the dataset. 4.1 Defining filters The types of filters that can be applied to the EBD fall into four categories: Species Region Season Protocol and effort Each specific filter is implemented by a different function in auk. Visit the documentation on filters on the auk website for a complete list. Each of these functions defines a filter on a column within the EBD. For example, auk_country() will define a filter allowing us to extract data from a subset of countries from the EBD. Tip Every filtering function in auk begins with auk_ for easy tab completion! To define a filter, start by creating an auk_ebd object, then pipe this into one of the filtering functions. library(auk) # output directory dir.create(&quot;data/&quot;, showWarnings = FALSE) auk_ebd(&quot;ebd_2014-2015_yucatan.txt&quot;) %&gt;% auk_country(&quot;Guatemala&quot;) #&gt; Input #&gt; EBD: /Users/mes335/data/ebird/ebd_2014-2015_yucatan.txt #&gt; #&gt; Output #&gt; Filters not executed #&gt; #&gt; Filters #&gt; Species: all #&gt; Countries: GT #&gt; States: all #&gt; BCRs: all #&gt; Bounding box: full extent #&gt; Date: all #&gt; Start time: all #&gt; Last edited date: all #&gt; Protocol: all #&gt; Project code: all #&gt; Duration: all #&gt; Distance travelled: all #&gt; Records with breeding codes only: no #&gt; Complete checklists only: no Notice that when the auk_ebd object is printed, it tells us what filters have been defined. At this point, nothing has been done to the EBD, we’ve just defined the filter, we haven’t executed it yet. Tip Consult the Function Reference section of the auk website for a full list of available filters. In general, you should think about filtering on region, season, and species, so let’s build upon what we already have and add some more filters. For example, if we wanted all Resplendent Quetzal records from Guatemala in June 2015 we would use the following filters: auk_ebd(&quot;ebd_2014-2015_yucatan.txt&quot;) %&gt;% auk_species(&quot;Resplendent Quetzal&quot;) %&gt;% auk_country(&quot;Guatemala&quot;) %&gt;% auk_date(c(&quot;2015-06-01&quot;, &quot;2015-06-30&quot;)) #&gt; Input #&gt; EBD: /Users/mes335/data/ebird/ebd_2014-2015_yucatan.txt #&gt; #&gt; Output #&gt; Filters not executed #&gt; #&gt; Filters #&gt; Species: Pharomachrus mocinno #&gt; Countries: GT #&gt; States: all #&gt; BCRs: all #&gt; Bounding box: full extent #&gt; Date: 2015-06-01 - 2015-06-30 #&gt; Start time: all #&gt; Last edited date: all #&gt; Protocol: all #&gt; Project code: all #&gt; Duration: all #&gt; Distance travelled: all #&gt; Records with breeding codes only: no #&gt; Complete checklists only: no Tip The filtering functions in auk check the arguments you provide and will throw an error if there’s something wrong. Filtering the EBD takes a long time, so it’s better to get an error now rather than realizing you made a mistake after waiting several hours for the extraction process to complete. auk_ebd(&quot;ebd_2014-2015_yucatan.txt&quot;) %&gt;% # typo in species name auk_species(&quot;Resplendant Quetzal&quot;) #&gt; Error in auk_species.auk_ebd(., &quot;Resplendant Quetzal&quot;): The following species were not found in the eBird taxonomy: #&gt; Resplendant Quetzal auk_ebd(&quot;ebd_2014-2015_yucatan.txt&quot;) %&gt;% # non-sequential dates auk_date(c(&quot;2015-06-01&quot;, &quot;2014-06-30&quot;)) #&gt; Error: date[1] not less than or equal to date[2] Exercise Define filters to extract Magnolia Warbler observations from Belize on checklists that started between 5 and 9 am and used either the “Traveling” or “Stationary” protocols. Consult the list of filters to see which ones you’ll need to use. Solution auk_ebd(&quot;ebd_2014-2015_yucatan.txt&quot;) %&gt;% auk_species(&quot;Magnolia Warbler&quot;) %&gt;% auk_country(&quot;BZ&quot;) %&gt;% auk_protocol(c(&quot;Traveling&quot;, &quot;Stationary&quot;)) %&gt;% auk_time(c(&quot;5:00&quot;, &quot;9:00&quot;)) #&gt; Input #&gt; EBD: /Users/mes335/data/ebird/ebd_2014-2015_yucatan.txt #&gt; #&gt; Output #&gt; Filters not executed #&gt; #&gt; Filters #&gt; Species: Setophaga magnolia #&gt; Countries: BZ #&gt; States: all #&gt; BCRs: all #&gt; Bounding box: full extent #&gt; Date: all #&gt; Start time: 05:00-09:00 #&gt; Last edited date: all #&gt; Protocol: Traveling, Stationary #&gt; Project code: all #&gt; Duration: all #&gt; Distance travelled: all #&gt; Records with breeding codes only: no #&gt; Complete checklists only: no Tip In general, when using the effort filters like auk_time() or auk_distance(), it’s best to be a bit coarse. You can always refine the filters later once the data are in R, and starting with a coarse filter gives you some wiggle room if you later realize you want to make adjustments. Remember: the initial filtering with auk takes a long time, it’s best to limit the number of times you do this. When filtering by date, you may need to extract records from a given date range regardless of year. For this situation, the auk_date() function can accept wildcards for the year. For example, we can rewrite the above Resplendent Quetzal example to get observations from June of any year. auk_ebd(&quot;ebd_2014-2015_yucatan.txt&quot;) %&gt;% auk_species(&quot;Resplendent Quetzal&quot;) %&gt;% auk_country(&quot;Guatemala&quot;) %&gt;% auk_date(c(&quot;*-06-01&quot;, &quot;*-06-30&quot;)) #&gt; Input #&gt; EBD: /Users/mes335/data/ebird/ebd_2014-2015_yucatan.txt #&gt; #&gt; Output #&gt; Filters not executed #&gt; #&gt; Filters #&gt; Species: Pharomachrus mocinno #&gt; Countries: GT #&gt; States: all #&gt; BCRs: all #&gt; Bounding box: full extent #&gt; Date: *-06-01 - *-06-30 #&gt; Start time: all #&gt; Last edited date: all #&gt; Protocol: all #&gt; Project code: all #&gt; Duration: all #&gt; Distance travelled: all #&gt; Records with breeding codes only: no #&gt; Complete checklists only: no 4.1.1 Complete checklists One of the most important filters is auk_complete(), which limits observations to those from complete checklists. As we’ve already seen, with complete checklists we can infer non-detections from the data. For most scientific applications, it’s critical that we have complete checklists, so we can generate presence-absence data. Exercise Define filters to extract Horned Guan and Highland Guan records from complete checklists in Chiapas, Mexico. Hint: look at the help for the auk_state() filter. Solution States are provided to auk_state() via 4-6 letter state codes. To find the state code, consult the ebird_states data frame or visit the Explore page on the eBird website and enter the state name under Explore Region. The state code will appear after region/ in the URL. For example, for Chiapas the URL is https://ebird.org/region/MX-CHP?yr=all and the state code is therefore MX-CHP. auk_ebd(&quot;ebd_2014-2015_yucatan.txt&quot;) %&gt;% auk_species(c(&quot;Horned Guan&quot;, &quot;Highland Guan&quot;)) %&gt;% auk_state(&quot;MX-CHP&quot;) %&gt;% auk_complete() #&gt; Input #&gt; EBD: /Users/mes335/data/ebird/ebd_2014-2015_yucatan.txt #&gt; #&gt; Output #&gt; Filters not executed #&gt; #&gt; Filters #&gt; Species: Oreophasis derbianus, Penelopina nigra #&gt; Countries: all #&gt; States: MX-CHP #&gt; BCRs: all #&gt; Bounding box: full extent #&gt; Date: all #&gt; Start time: all #&gt; Last edited date: all #&gt; Protocol: all #&gt; Project code: all #&gt; Duration: all #&gt; Distance travelled: all #&gt; Records with breeding codes only: no #&gt; Complete checklists only: yes Checkpoint Are there any questions about defining filters on the EBD? 4.2 Execute filters Once you have an auk_ebd object with a set of filters defined, you can execute those filters with auk_filter(). This function compiles the filters into an AWK script, then runs that script to produce a text file with the defined subset of the EBD. The processing with AWK is done outside of R, line by line, only selecting rows that meet the criteria specified in the various auk filters. We’ll store the output file within the data/ subdirectory of the project directory. Note that filtering on the full EBD will take at least a couple hours, so be prepared to wait awhile. Let’s define filters to extract Yellow-rumped Warbler observations in Guatemala that appear on complete traveling or stationary checklists, then execute those filters. ebd_filtered &lt;- auk_ebd(&quot;ebd_2014-2015_yucatan.txt&quot;) %&gt;% auk_species(&quot;Yellow-rumped Warbler&quot;) %&gt;% auk_country(&quot;GT&quot;) %&gt;% auk_protocol(c(&quot;Traveling&quot;, &quot;Stationary&quot;)) %&gt;% auk_complete() %&gt;% auk_filter(file = &quot;data/ebd_yerwar.txt&quot;) Take a look at this file and notice that we’ve drastically reduced the size. It can now be imported into R without any issues. Checkpoint Were you able to correctly extract the Yellow-rumped Warbler data? Any questions on filtering? "],
["import.html", "Lesson 5 Importing Data 5.1 Group checklists 5.2 Taxonomy", " Lesson 5 Importing Data In the previous lesson, we extracted a subset of the EBD containing Yellow-rumped Warbler observations from Guatemala. The output file created by auk_filter() is a tab-separated text file and could be read into R using read.delim() or readr::read_tsv(); however, auk has a function specifically for reading the EBD. read_ebd() does the following: Reads the data using data.table::fread(), which is much faster than read.delim(). Sets the correct data types for the columns. Cleans up the column names so they are all snake_case. Automatically performs some post processing steps, which will be covered later in this lesson. Let’s read in the data! library(auk) library(tidyverse) ebd &lt;- read_ebd(&quot;data/ebd_yerwar.txt&quot;, unique = FALSE, rollup = FALSE) glimpse(ebd) #&gt; Observations: 160 #&gt; Variables: 46 #&gt; $ global_unique_identifier &lt;chr&gt; &quot;URN:CornellLabOfOrnithology:EBIRD:OBS239833810&quot;, &quot;URN:CornellLabOfOrnithology:E… #&gt; $ last_edited_date &lt;chr&gt; &quot;2018-09-09 12:59:27&quot;, &quot;2017-08-29 11:00:49&quot;, &quot;2014-04-03 23:33:43&quot;, &quot;2015-06-23… #&gt; $ taxonomic_order &lt;dbl&gt; 32863, 32859, 32858, 32858, 32858, 32863, 32859, 32860, 32858, 32858, 32858, 328… #&gt; $ category &lt;chr&gt; &quot;issf&quot;, &quot;issf&quot;, &quot;species&quot;, &quot;species&quot;, &quot;species&quot;, &quot;issf&quot;, &quot;issf&quot;, &quot;issf&quot;, &quot;specie… #&gt; $ common_name &lt;chr&gt; &quot;Yellow-rumped Warbler&quot;, &quot;Yellow-rumped Warbler&quot;, &quot;Yellow-rumped Warbler&quot;, &quot;Yell… #&gt; $ scientific_name &lt;chr&gt; &quot;Setophaga coronata&quot;, &quot;Setophaga coronata&quot;, &quot;Setophaga coronata&quot;, &quot;Setophaga cor… #&gt; $ subspecies_common_name &lt;chr&gt; &quot;Yellow-rumped Warbler (Goldman&#39;s)&quot;, &quot;Yellow-rumped Warbler (Myrtle)&quot;, NA, NA, N… #&gt; $ subspecies_scientific_name &lt;chr&gt; &quot;Setophaga coronata goldmani&quot;, &quot;Setophaga coronata coronata&quot;, NA, NA, NA, &quot;Setop… #&gt; $ observation_count &lt;chr&gt; &quot;12&quot;, &quot;8&quot;, &quot;11&quot;, &quot;3&quot;, &quot;1&quot;, &quot;15&quot;, &quot;4&quot;, &quot;X&quot;, &quot;3&quot;, &quot;X&quot;, &quot;X&quot;, &quot;2&quot;, &quot;1&quot;, &quot;20&quot;, &quot;1&quot;, &quot;… #&gt; $ breeding_bird_atlas_code &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #&gt; $ breeding_bird_atlas_category &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #&gt; $ age_sex &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;Female, Adu… #&gt; $ country &lt;chr&gt; &quot;Guatemala&quot;, &quot;Guatemala&quot;, &quot;Guatemala&quot;, &quot;Guatemala&quot;, &quot;Guatemala&quot;, &quot;Guatemala&quot;, &quot;G… #&gt; $ country_code &lt;chr&gt; &quot;GT&quot;, &quot;GT&quot;, &quot;GT&quot;, &quot;GT&quot;, &quot;GT&quot;, &quot;GT&quot;, &quot;GT&quot;, &quot;GT&quot;, &quot;GT&quot;, &quot;GT&quot;, &quot;GT&quot;, &quot;GT&quot;, &quot;GT&quot;, &quot;G… #&gt; $ state &lt;chr&gt; &quot;Huehuetenango&quot;, &quot;Petén&quot;, &quot;Huehuetenango&quot;, &quot;Jalapa&quot;, &quot;Quetzaltenango&quot;, &quot;Huehuete… #&gt; $ state_code &lt;chr&gt; &quot;GT-HU&quot;, &quot;GT-PE&quot;, &quot;GT-HU&quot;, &quot;GT-JA&quot;, &quot;GT-QZ&quot;, &quot;GT-HU&quot;, &quot;GT-PE&quot;, &quot;GT-PE&quot;, &quot;GT-PE&quot;,… #&gt; $ county &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #&gt; $ county_code &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #&gt; $ iba_code &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #&gt; $ bcr_code &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #&gt; $ usfws_code &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #&gt; $ atlas_block &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #&gt; $ locality &lt;chr&gt; &quot;Cerro de los Cuervos&quot;, &quot;Tikal Area&quot;, &quot;Capellania to La Ventosa&quot;, &quot;Cerro Alto, J… #&gt; $ locality_id &lt;chr&gt; &quot;L2713729&quot;, &quot;L4754006&quot;, &quot;L2713730&quot;, &quot;L3222877&quot;, &quot;L1380407&quot;, &quot;L2713729&quot;, &quot;L475400… #&gt; $ locality_type &lt;chr&gt; &quot;P&quot;, &quot;P&quot;, &quot;P&quot;, &quot;P&quot;, &quot;H&quot;, &quot;P&quot;, &quot;P&quot;, &quot;P&quot;, &quot;P&quot;, &quot;H&quot;, &quot;P&quot;, &quot;P&quot;, &quot;H&quot;, &quot;P&quot;, &quot;H&quot;, &quot;H&quot;, … #&gt; $ latitude &lt;dbl&gt; 15.5, 17.2, 15.5, 14.7, 14.7, 15.5, 17.2, 17.2, 17.2, 15.2, 17.2, 17.2, 17.2, 14… #&gt; $ longitude &lt;dbl&gt; -91.5, -89.6, -91.5, -90.0, -91.5, -91.5, -89.6, -89.6, -90.3, -90.2, -89.6, -89… #&gt; $ observation_date &lt;date&gt; 2014-03-07, 2014-01-19, 2014-03-05, 2014-01-26, 2014-12-24, 2014-03-05, 2014-01… #&gt; $ time_observations_started &lt;chr&gt; &quot;07:10:00&quot;, &quot;14:00:00&quot;, &quot;10:55:00&quot;, &quot;06:30:00&quot;, &quot;09:00:00&quot;, &quot;06:15:00&quot;, &quot;14:00:0… #&gt; $ observer_id &lt;chr&gt; &quot;obsr200421&quot;, &quot;obsr837809&quot;, &quot;obsr200421&quot;, &quot;obsr411126&quot;, &quot;obsr553524&quot;, &quot;obsr32598… #&gt; $ sampling_event_identifier &lt;chr&gt; &quot;S17445204&quot;, &quot;S36593691&quot;, &quot;S17445203&quot;, &quot;S20932409&quot;, &quot;S21010046&quot;, &quot;S17445397&quot;, &quot;S… #&gt; $ protocol_type &lt;chr&gt; &quot;Traveling&quot;, &quot;Traveling&quot;, &quot;Traveling&quot;, &quot;Traveling&quot;, &quot;Traveling&quot;, &quot;Traveling&quot;, &quot;T… #&gt; $ protocol_code &lt;chr&gt; &quot;P22&quot;, &quot;P22&quot;, &quot;P22&quot;, &quot;P22&quot;, &quot;P22&quot;, &quot;P22&quot;, &quot;P22&quot;, &quot;P22&quot;, &quot;P22&quot;, &quot;P22&quot;, &quot;P22&quot;, &quot;P2… #&gt; $ project_code &lt;chr&gt; &quot;EBIRD&quot;, &quot;EBIRD&quot;, &quot;EBIRD&quot;, &quot;EBIRD&quot;, &quot;EBIRD&quot;, &quot;EBIRD&quot;, &quot;EBIRD&quot;, &quot;EBIRD&quot;, &quot;EBIRD&quot;,… #&gt; $ duration_minutes &lt;int&gt; 170, 210, 55, 300, 120, 210, 180, 240, 60, 300, 240, 180, 60, 60, 60, 210, 120, … #&gt; $ effort_distance_km &lt;dbl&gt; 2.01, 1.61, 4.83, 5.00, 2.41, 2.01, 1.61, 3.22, 0.50, 3.22, 3.22, 0.25, 2.00, NA… #&gt; $ effort_area_ha &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #&gt; $ number_observers &lt;int&gt; 2, 3, 3, 6, 1, 3, 3, 14, 4, 12, 14, 1, 2, 3, 6, 2, 3, 2, 2, 2, 2, 3, 3, 3, 4, 2,… #&gt; $ all_species_reported &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… #&gt; $ group_identifier &lt;chr&gt; &quot;G828557&quot;, &quot;G2390002&quot;, &quot;G828560&quot;, NA, &quot;G1125157&quot;, &quot;G828561&quot;, &quot;G2390003&quot;, NA, NA,… #&gt; $ has_media &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALS… #&gt; $ approved &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… #&gt; $ reviewed &lt;lgl&gt; TRUE, FALSE, TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,… #&gt; $ reason &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #&gt; $ trip_comments &lt;chr&gt; NA, NA, &quot;Driving w/ stops&quot;, NA, &quot;Walked up the trail from the hot springs to rid… #&gt; $ species_comments &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &quot;subespecie Audubon. Todos l… We’ll cover the use of unique = FALSE and rollup = FALSE next. For now, let’s just look at the data. Exercise Take a minute to explore these data using glimpse() and View(). Familiarize yourself with the columns. Be sure you can find the effort columns and the observation_count column. Checkpoint Do you have the data in a data frame? Does anyone have any questions about the data so far? 5.1 Group checklists eBird allows users to share checklists with other eBird users that they’re birding with. This results it multiple copies of some checklists in the database. Group checklists can be identified in the data because they have the group_identifier column populated. Let’s take a look at some these checklists. ebd %&gt;% filter(!is.na(group_identifier)) %&gt;% arrange(group_identifier) %&gt;% select(sampling_event_identifier, group_identifier) %&gt;% head() #&gt; # A tibble: 6 x 2 #&gt; sampling_event_identifier group_identifier #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 S20741847 G1059449 #&gt; 2 S20713245 G1059449 #&gt; 3 S20713307 G1059450 #&gt; 4 S20741848 G1059450 #&gt; 5 S20925877 G1072982 #&gt; 6 S20929011 G1072982 We see that there are multiple checklists with the same group_identifier, implying that these checklists have been shared and are duplicates. Let’s look at one of these on the eBird website: https://ebird.org/view/checklist/S20741847 As it turns out, group checklists aren’t exact duplicates; once a checklist has been shared the individual checklists can diverge in terms of the species seen, the counts for each species, and even the protocol and effort. For an example, look at this checklist with six observers each of whom saw a different set of species. In most cases, you’ll only want to retain one of these checklists, but it’s not trivial to do so because the checklists are only partial duplicates. The function auk_unique() manages this for you. Specifically, for each species, it retains only the first observation of that species, which is typically the one submitted by the primary observer (i.e. the person who submit the checklist to eBird). Note that the resulting “checklist” will be a combination of all the species seen across all copies of the group checklist. keep_one &lt;- auk_unique(ebd) nrow(ebd) #&gt; [1] 160 nrow(keep_one) #&gt; [1] 104 When auk_unique() is run, a new field is created (checklist_id), which is populated with group_identifier for group checklists and sampling_event_identifier otherwise; this is now a unique identifier for checklists. In addition, the full set of observer and sampling event identifiers has been retained in a comma separated format. keep_one %&gt;% filter(!is.na(group_identifier)) %&gt;% select(checklist_id, sampling_event_identifier, group_identifier, observer_id) %&gt;% head() #&gt; # A tibble: 6 x 4 #&gt; checklist_id sampling_event_identifier group_identifier observer_id #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 G828558 S17445097,S17445389 G828558 obsr200421,obsr325989 #&gt; 2 G828561 S17445202,S17445397 G828561 obsr200421,obsr325989 #&gt; 3 G828560 S17445203,S17445396 G828560 obsr200421,obsr325989 #&gt; 4 G828557 S17445204,S17445204,S17445386,S17445386 G828557 obsr200421,obsr200421,obsr325989,obsr325989 #&gt; 5 G828555 S17445206,S17445382 G828555 obsr200421,obsr325989 #&gt; 6 G828571 S17445344,S17445420 G828571 obsr200421,obsr325989 By default, whenever you import data with read_ebd() it calls auk_unique() automatically; however, this behavior can be controlled with the unique argument. So, for example, the following will import data and remove duplicates. ebd &lt;- read_ebd(&quot;data/ebd_yerwar.txt&quot;, rollup = FALSE) Tip auk_unique() takes a long time to run on large datasets. Consider using read_ebd(unique = FALSE) when importing large text files to speed up the process. 5.2 Taxonomy eBird users can enter data for a wide range of taxa in addition to species. Observations can be reported at a level more granular than species (e.g. subspecies or recognizable forms) or at a higher level than species (e.g. spuhs, slashes, and hybrids). All the different taxa that can be reported are contained in the eBird taxonomy, which is updated every year in August. The eBird Science page has a subsection with details on the eBird taxonomy, and the taxonomy itself is available as a data frame in the auk package. glimpse(ebird_taxonomy) #&gt; Observations: 16,513 #&gt; Variables: 9 #&gt; $ species_code &lt;chr&gt; &quot;ostric2&quot;, &quot;ostric3&quot;, &quot;y00934&quot;, &quot;grerhe1&quot;, &quot;lesrhe2&quot;, &quot;lesrhe4&quot;, &quot;lesrhe3&quot;, &quot;tabtin1&quot;, &quot;higti… #&gt; $ scientific_name &lt;chr&gt; &quot;Struthio camelus&quot;, &quot;Struthio molybdophanes&quot;, &quot;Struthio camelus/molybdophanes&quot;, &quot;Rhea america… #&gt; $ common_name &lt;chr&gt; &quot;Common Ostrich&quot;, &quot;Somali Ostrich&quot;, &quot;Common/Somali Ostrich&quot;, &quot;Greater Rhea&quot;, &quot;Lesser Rhea&quot;, &quot;… #&gt; $ order &lt;chr&gt; &quot;Struthioniformes&quot;, &quot;Struthioniformes&quot;, &quot;Struthioniformes&quot;, &quot;Rheiformes&quot;, &quot;Rheiformes&quot;, &quot;Rhei… #&gt; $ family &lt;chr&gt; &quot;Struthionidae (Ostriches)&quot;, &quot;Struthionidae (Ostriches)&quot;, &quot;Struthionidae (Ostriches)&quot;, &quot;Rheid… #&gt; $ family_common &lt;chr&gt; &quot;Ostriches&quot;, &quot;Ostriches&quot;, &quot;Ostriches&quot;, &quot;Rheas&quot;, &quot;Rheas&quot;, &quot;Rheas&quot;, &quot;Rheas&quot;, &quot;Tinamous&quot;, &quot;Tinam… #&gt; $ category &lt;chr&gt; &quot;species&quot;, &quot;species&quot;, &quot;slash&quot;, &quot;species&quot;, &quot;species&quot;, &quot;issf&quot;, &quot;issf&quot;, &quot;species&quot;, &quot;species&quot;, &quot;i… #&gt; $ taxon_order &lt;dbl&gt; 1, 6, 7, 8, 14, 15, 18, 19, 20, 21, 26, 27, 30, 35, 36, 39, 52, 53, 54, 55, 56, 71, 72, 73, 7… #&gt; $ report_as &lt;chr&gt; NA, NA, NA, NA, NA, &quot;lesrhe2&quot;, &quot;lesrhe2&quot;, NA, NA, &quot;higtin1&quot;, &quot;higtin1&quot;, NA, NA, NA, NA, NA, N… # you can even report that you saw a generic bird! filter(ebird_taxonomy, common_name == &quot;bird sp.&quot;) #&gt; species_code scientific_name common_name order family family_common category taxon_order report_as #&gt; 1 bird1 Aves sp. bird sp. &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; spuh 34501 &lt;NA&gt; For taxa below the species level, the report_as field specifies the species that this taxa falls under. For example, Myrtle warbler rolls up to Yellow-rumped Warbler. # myrtle warbler filter(ebird_taxonomy, common_name == &quot;Yellow-rumped Warbler (Myrtle)&quot;) %&gt;% select(common_name, category, report_as) #&gt; common_name category report_as #&gt; 1 Yellow-rumped Warbler (Myrtle) issf yerwar # rolls up to yellow-rumped warbler filter(ebird_taxonomy, species_code == &quot;yerwar&quot;) %&gt;% select(common_name, category, report_as) #&gt; common_name category report_as #&gt; 1 Yellow-rumped Warbler species &lt;NA&gt; Exercise How many different subspecies of Barn Swallow does eBird recognize? Solution Start by finding the species code for Barn Swallow, then find records in ebird_taxonomy with this code in the report_as column. ebird_taxonomy %&gt;% filter(common_name == &quot;Barn Swallow&quot;) %&gt;% select(common_name, species_code) #&gt; common_name species_code #&gt; 1 Barn Swallow barswa ebird_taxonomy %&gt;% filter(report_as == &quot;barswa&quot;) %&gt;% select(common_name, category, report_as) #&gt; common_name category report_as #&gt; 1 Barn Swallow (White-bellied) issf barswa #&gt; 2 Barn Swallow (Egyptian) issf barswa #&gt; 3 Barn Swallow (Levant) issf barswa #&gt; 4 Barn Swallow (Tytler&#39;s) issf barswa #&gt; 5 Barn Swallow (Buff-bellied) issf barswa #&gt; 6 Barn Swallow (American) issf barswa eBird recognizes six subspecies. The EBD contains a subspecies column, which is populated when an observer has identified a bird below species level. In the EBD extract we’re working with, we have three different subspecies of Yellow-rumped Warbler: count(ebd, common_name, subspecies_common_name) #&gt; # A tibble: 4 x 3 #&gt; common_name subspecies_common_name n #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Yellow-rumped Warbler Yellow-rumped Warbler (Audubon&#39;s) 27 #&gt; 2 Yellow-rumped Warbler Yellow-rumped Warbler (Goldman&#39;s) 4 #&gt; 3 Yellow-rumped Warbler Yellow-rumped Warbler (Myrtle) 16 #&gt; 4 Yellow-rumped Warbler &lt;NA&gt; 57 It’s even possible to have multiple subspecies of the same species on a single checklist. filter(ebd, checklist_id == &quot;S22725024&quot;) %&gt;% select(checklist_id, common_name, subspecies_common_name, observation_count) #&gt; # A tibble: 2 x 4 #&gt; checklist_id common_name subspecies_common_name observation_count #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 S22725024 Yellow-rumped Warbler Yellow-rumped Warbler (Audubon&#39;s) 1 #&gt; 2 S22725024 Yellow-rumped Warbler Yellow-rumped Warbler (Myrtle) 1 For most uses, you’ll want eBird data at the species level, which means dropping higher level taxa and rolling lower level taxa up to species level, making sure to sum the counts if multiple subspecies were present. The function auk_rollup() handles these taxonomic matters for you. no_subsp &lt;- auk_rollup(ebd) no_subsp %&gt;% filter(checklist_id == &quot;S22725024&quot;) %&gt;% select(checklist_id, common_name, observation_count) #&gt; # A tibble: 1 x 3 #&gt; checklist_id common_name observation_count #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 S22725024 Yellow-rumped Warbler 2 By default, when you import data with read_ebd() it calls auk_rollup() automatically; however, this behavior can be controlled with the rollup argument. So, for example, the following will import data and remove duplicates and report all records at species level. ebd &lt;- read_ebd(&quot;data/ebd_yerwar.txt&quot;) Checkpoint Any questions on data import, taxonomy, or group checklists? "],
["presabs.html", "Lesson 6 Presence-absence Data 6.1 Filtering 6.2 Zero-filling 6.3 Tidying up", " Lesson 6 Presence-absence Data Up to this point we’ve been working with presence-only data. The EBD, and eBird checklists in general, only explicitly record positive observations of species. However, if we limit ourselves to complete checklists, we can fill in the implied zero counts for any checklists on which a given species isn’t explicitly reported to generate presence-absence data. We refer to this process as zero-filling the eBird data. Zero-filling relies on the Sampling Event Data, which is a tab-seperated text file containing checklist-level information. This file contains the full population of checklists in the eBird database. If we apply exactly the same set of filters to both the EBD and the Sampling Event Data we can assume that any checklist with no observations for a given species in the EBD should get a zero-count record added to the dataset. So, producing presence-absence eBird data is a two-step process: Simultaneously filter the EBD and Sampling Event Data, making sure to only use complete checklists. Read both files into R and zero-fill the EBD using the full population of checklists from the Sampling Event Data. Tip When we say “presence-absence” what we really mean by “absence” is that the species was not detected, it’s entirely possible that the species was present, but the observer didn’t detect it. Checkpoint Are there any conceptual questions about the process of zero-filling? 6.1 Filtering Simultaneously filtering the EBD and Sampling Event Data is done in almost the exact same way as filtering the EBD alone. The only difference is that we provide both files to auk_ebd() and two corresponding output files to auk_filter(). For example, we can extract all American Flamingo observations from January in the Mexican state of Yucatán in preparation for zero-filling. library(auk) library(tidyverse) f_ebd &lt;- &quot;data/ebd_amefla.txt&quot; f_sed &lt;- &quot;data/sed_amefla.txt&quot; ebd_amefla &lt;- auk_ebd(&quot;ebd_2014-2015_yucatan.txt&quot;, file_sampling = &quot;ebd_sampling_2014-2015_yucatan.txt&quot;) %&gt;% auk_species(&quot;American Flamingo&quot;) %&gt;% auk_state(&quot;MX-YUC&quot;) %&gt;% auk_date(c(&quot;*-01-01&quot;, &quot;*-01-31&quot;)) %&gt;% auk_complete() %&gt;% auk_filter(f_ebd, file_sampling = f_sed) We now have two output files that have been extracted using the same set of filters, apart from the species filter, which only applies to the EBD. We can read these files into R individually: ebd_only &lt;- read_ebd(f_ebd) sed_only &lt;- read_sampling(f_sed) nrow(ebd_only) #&gt; [1] 47 nrow(sed_only) #&gt; [1] 291 So, we have 291 checklists in the Sampling Event Data and, of those, 47 have Flamingo observations on them. Checkpoint Were you able to filter and import the EBD and Sampling Event Data? Did you get the correct number of rows in both files? Exercise You’re studying Hooded Warblers wintering (November-February) in Belize. Extract eBird data in preparation for zero-filling, then read in the results and explore them. Hint: consult the Details section of the documentation for auk_date() to see how to filter a range of dates that wrap around the year end. Solution f_ebd_hw &lt;- &quot;data/ebd_hoowar.txt&quot; f_sed_hw &lt;- &quot;data/sed_hoowar.txt&quot; # filter ebd_hoowar &lt;- auk_ebd(&quot;ebd_2014-2015_yucatan.txt&quot;, file_sampling = &quot;ebd_sampling_2014-2015_yucatan.txt&quot;) %&gt;% auk_species(&quot;Hooded Warbler&quot;) %&gt;% auk_country(&quot;BZ&quot;) %&gt;% # when using wildcards, dates can wrap around the year end auk_date(c(&quot;*-11-01&quot;, &quot;*-02-29&quot;)) %&gt;% auk_complete() %&gt;% auk_filter(f_ebd_hw, file_sampling = f_sed_hw) # import the data ebd_only_hw &lt;- read_ebd(f_ebd_hw) sed_only_hw &lt;- read_sampling(f_sed_hw) 6.2 Zero-filling Now that we have these two datasets–containing checklist and species information, respectively–we can use the function auk_zerofill() to combine them to produce presence-absence data. This function also imports the data, and handles group checklists and taxonomic rollup automatically, we just have to pass it the paths to the two files. Let’s do this with the American Flamingo data. ebd_zf &lt;- auk_zerofill(f_ebd, sampling_events = f_sed) ebd_zf #&gt; Zero-filled EBD: 291 unique checklists, for 1 species. By default, auk_zerofill() returns the data as a list of two dataframes: sampling_events contains all the checklist and observations contains just the counts and presence-absence data for each species on each checklist. This compact format reduces the size of the data because checklist information isn’t replicated for every species observation. glimpse(ebd_zf$observations) #&gt; Observations: 291 #&gt; Variables: 4 #&gt; $ checklist_id &lt;chr&gt; &quot;G1089999&quot;, &quot;G1092350&quot;, &quot;G1095290&quot;, &quot;G1095467&quot;, &quot;G1097421&quot;, &quot;G1097595&quot;, &quot;G1097630&quot;, &quot;G10976… #&gt; $ scientific_name &lt;chr&gt; &quot;Phoenicopterus ruber&quot;, &quot;Phoenicopterus ruber&quot;, &quot;Phoenicopterus ruber&quot;, &quot;Phoenicopterus rub… #&gt; $ observation_count &lt;chr&gt; &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;3&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;200&quot;, &quot;0&quot;, &quot;0&quot;, &quot;100&quot;, &quot;0&quot;, &quot;175&quot;, &quot;0&quot;, &quot;0&quot;, … #&gt; $ species_observed &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, TRUE, FAL… glimpse(ebd_zf$sampling_events) #&gt; Observations: 291 #&gt; Variables: 31 #&gt; $ checklist_id &lt;chr&gt; &quot;S16201726&quot;, &quot;S21515362&quot;, &quot;S21431825&quot;, &quot;S44603056&quot;, &quot;S16508737&quot;, &quot;S16718542&quot;, &quot;S165… #&gt; $ last_edited_date &lt;chr&gt; &quot;2014-01-03 11:28:47&quot;, &quot;2015-01-24 11:45:17&quot;, &quot;2019-09-25 00:29:42&quot;, &quot;2018-04-15 14… #&gt; $ country &lt;chr&gt; &quot;Mexico&quot;, &quot;Mexico&quot;, &quot;Mexico&quot;, &quot;Mexico&quot;, &quot;Mexico&quot;, &quot;Mexico&quot;, &quot;Mexico&quot;, &quot;Mexico&quot;, &quot;Me… #&gt; $ country_code &lt;chr&gt; &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;,… #&gt; $ state &lt;chr&gt; &quot;Yucatán&quot;, &quot;Yucatán&quot;, &quot;Yucatán&quot;, &quot;Yucatán&quot;, &quot;Yucatán&quot;, &quot;Yucatán&quot;, &quot;Yucatán&quot;, &quot;Yucat… #&gt; $ state_code &lt;chr&gt; &quot;MX-YUC&quot;, &quot;MX-YUC&quot;, &quot;MX-YUC&quot;, &quot;MX-YUC&quot;, &quot;MX-YUC&quot;, &quot;MX-YUC&quot;, &quot;MX-YUC&quot;, &quot;MX-YUC&quot;, &quot;MX… #&gt; $ county &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #&gt; $ county_code &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #&gt; $ iba_code &lt;chr&gt; NA, &quot;MX_183&quot;, &quot;MX_183&quot;, NA, NA, NA, NA, &quot;MX_183&quot;, NA, NA, &quot;MX_184&quot;, NA, &quot;MX_183&quot;, N… #&gt; $ bcr_code &lt;int&gt; 56, 55, 55, 55, 55, 55, 55, 55, 56, 56, 55, 56, 55, 55, 56, 56, 55, NA, 55, 55, 56,… #&gt; $ usfws_code &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #&gt; $ atlas_block &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #&gt; $ locality &lt;chr&gt; &quot;VALLADOLID&quot;, &quot;Celestun Casa Palmera&quot;, &quot;Celestun Casa Palmera&quot;, &quot;Jardín Botánico Re… #&gt; $ locality_id &lt;chr&gt; &quot;L2502912&quot;, &quot;L3305787&quot;, &quot;L3305787&quot;, &quot;L3626918&quot;, &quot;L1111317&quot;, &quot;L2575191&quot;, &quot;L2582781&quot;,… #&gt; $ locality_type &lt;chr&gt; &quot;P&quot;, &quot;P&quot;, &quot;P&quot;, &quot;H&quot;, &quot;H&quot;, &quot;H&quot;, &quot;P&quot;, &quot;P&quot;, &quot;P&quot;, &quot;P&quot;, &quot;H&quot;, &quot;P&quot;, &quot;P&quot;, &quot;H&quot;, &quot;P&quot;, &quot;P&quot;, &quot;P&quot;… #&gt; $ latitude &lt;dbl&gt; 20.7, 20.9, 20.9, 21.0, 20.7, 21.0, 21.1, 20.9, 20.5, 20.4, 21.3, 20.7, 21.2, 21.0,… #&gt; $ longitude &lt;dbl&gt; -88.2, -90.4, -90.4, -89.6, -89.7, -89.6, -89.6, -90.4, -89.7, -89.8, -89.6, -88.2,… #&gt; $ observation_date &lt;date&gt; 2014-01-01, 2015-01-24, 2015-01-20, 2014-01-22, 2014-01-25, 2014-01-18, 2014-01-24… #&gt; $ time_observations_started &lt;chr&gt; &quot;10:15:00&quot;, &quot;09:00:00&quot;, &quot;06:45:00&quot;, &quot;06:30:00&quot;, &quot;08:30:00&quot;, &quot;06:45:00&quot;, &quot;23:30:00&quot;,… #&gt; $ observer_id &lt;chr&gt; &quot;obs439605&quot;, &quot;obs170749&quot;, &quot;obs170749&quot;, &quot;obs282508&quot;, &quot;obs332036&quot;, &quot;obs439605&quot;, &quot;obs3… #&gt; $ sampling_event_identifier &lt;chr&gt; &quot;S16201726&quot;, &quot;S21515362&quot;, &quot;S21431825&quot;, &quot;S44603056&quot;, &quot;S16508737&quot;, &quot;S16718542&quot;, &quot;S165… #&gt; $ protocol_type &lt;chr&gt; &quot;Traveling&quot;, &quot;Stationary&quot;, &quot;Traveling&quot;, &quot;Traveling&quot;, &quot;Stationary&quot;, &quot;Traveling&quot;, &quot;St… #&gt; $ protocol_code &lt;chr&gt; &quot;P22&quot;, &quot;P21&quot;, &quot;P22&quot;, &quot;P22&quot;, &quot;P21&quot;, &quot;P22&quot;, &quot;P21&quot;, &quot;P22&quot;, &quot;P22&quot;, &quot;P22&quot;, &quot;P21&quot;, &quot;P20&quot;,… #&gt; $ project_code &lt;chr&gt; &quot;EBIRD_MEX&quot;, &quot;EBIRD&quot;, &quot;EBIRD&quot;, &quot;EBIRD&quot;, &quot;EBIRD&quot;, &quot;EBIRD_MEX&quot;, &quot;EBIRD&quot;, &quot;EBIRD&quot;, &quot;EB… #&gt; $ duration_minutes &lt;int&gt; 90, 150, 120, 45, 30, 120, 5, 450, 105, 150, 5, NA, 3, 75, NA, 75, 30, 255, 140, 40… #&gt; $ effort_distance_km &lt;dbl&gt; 1.609, NA, 0.322, 0.322, NA, 2.000, NA, 40.234, 2.414, 2.000, NA, NA, NA, 3.000, NA… #&gt; $ effort_area_ha &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #&gt; $ number_observers &lt;int&gt; 4, 1, 1, 2, 2, 1, 1, 3, 13, 1, 1, 5, 5, 1, 4, 4, 1, 13, 1, 3, 4, 12, 3, 5, 2, 6, 9,… #&gt; $ all_species_reported &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,… #&gt; $ group_identifier &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #&gt; $ trip_comments &lt;chr&gt; &quot;RECORRIDO POR UNA HACIENDA.&quot;, &quot;from patio&quot;, NA, &quot;Bob and Prudy Bowers birded area … However, in this case object size isn’t an issue, and it’s easier to work with a single dataframe, so we can collapse the data with collapse_zerofill(). ebd_zf_df &lt;- collapse_zerofill(ebd_zf) glimpse(ebd_zf_df) #&gt; Observations: 291 #&gt; Variables: 34 #&gt; $ checklist_id &lt;chr&gt; &quot;S16201726&quot;, &quot;S21515362&quot;, &quot;S21431825&quot;, &quot;S44603056&quot;, &quot;S16508737&quot;, &quot;S16718542&quot;, &quot;S165… #&gt; $ last_edited_date &lt;chr&gt; &quot;2014-01-03 11:28:47&quot;, &quot;2015-01-24 11:45:17&quot;, &quot;2019-09-25 00:29:42&quot;, &quot;2018-04-15 14… #&gt; $ country &lt;chr&gt; &quot;Mexico&quot;, &quot;Mexico&quot;, &quot;Mexico&quot;, &quot;Mexico&quot;, &quot;Mexico&quot;, &quot;Mexico&quot;, &quot;Mexico&quot;, &quot;Mexico&quot;, &quot;Me… #&gt; $ country_code &lt;chr&gt; &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;, &quot;MX&quot;,… #&gt; $ state &lt;chr&gt; &quot;Yucatán&quot;, &quot;Yucatán&quot;, &quot;Yucatán&quot;, &quot;Yucatán&quot;, &quot;Yucatán&quot;, &quot;Yucatán&quot;, &quot;Yucatán&quot;, &quot;Yucat… #&gt; $ state_code &lt;chr&gt; &quot;MX-YUC&quot;, &quot;MX-YUC&quot;, &quot;MX-YUC&quot;, &quot;MX-YUC&quot;, &quot;MX-YUC&quot;, &quot;MX-YUC&quot;, &quot;MX-YUC&quot;, &quot;MX-YUC&quot;, &quot;MX… #&gt; $ county &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #&gt; $ county_code &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #&gt; $ iba_code &lt;chr&gt; NA, &quot;MX_183&quot;, &quot;MX_183&quot;, NA, NA, NA, NA, &quot;MX_183&quot;, NA, NA, &quot;MX_184&quot;, NA, &quot;MX_183&quot;, N… #&gt; $ bcr_code &lt;int&gt; 56, 55, 55, 55, 55, 55, 55, 55, 56, 56, 55, 56, 55, 55, 56, 56, 55, NA, 55, 55, 56,… #&gt; $ usfws_code &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #&gt; $ atlas_block &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #&gt; $ locality &lt;chr&gt; &quot;VALLADOLID&quot;, &quot;Celestun Casa Palmera&quot;, &quot;Celestun Casa Palmera&quot;, &quot;Jardín Botánico Re… #&gt; $ locality_id &lt;chr&gt; &quot;L2502912&quot;, &quot;L3305787&quot;, &quot;L3305787&quot;, &quot;L3626918&quot;, &quot;L1111317&quot;, &quot;L2575191&quot;, &quot;L2582781&quot;,… #&gt; $ locality_type &lt;chr&gt; &quot;P&quot;, &quot;P&quot;, &quot;P&quot;, &quot;H&quot;, &quot;H&quot;, &quot;H&quot;, &quot;P&quot;, &quot;P&quot;, &quot;P&quot;, &quot;P&quot;, &quot;H&quot;, &quot;P&quot;, &quot;P&quot;, &quot;H&quot;, &quot;P&quot;, &quot;P&quot;, &quot;P&quot;… #&gt; $ latitude &lt;dbl&gt; 20.7, 20.9, 20.9, 21.0, 20.7, 21.0, 21.1, 20.9, 20.5, 20.4, 21.3, 20.7, 21.2, 21.0,… #&gt; $ longitude &lt;dbl&gt; -88.2, -90.4, -90.4, -89.6, -89.7, -89.6, -89.6, -90.4, -89.7, -89.8, -89.6, -88.2,… #&gt; $ observation_date &lt;date&gt; 2014-01-01, 2015-01-24, 2015-01-20, 2014-01-22, 2014-01-25, 2014-01-18, 2014-01-24… #&gt; $ time_observations_started &lt;chr&gt; &quot;10:15:00&quot;, &quot;09:00:00&quot;, &quot;06:45:00&quot;, &quot;06:30:00&quot;, &quot;08:30:00&quot;, &quot;06:45:00&quot;, &quot;23:30:00&quot;,… #&gt; $ observer_id &lt;chr&gt; &quot;obs439605&quot;, &quot;obs170749&quot;, &quot;obs170749&quot;, &quot;obs282508&quot;, &quot;obs332036&quot;, &quot;obs439605&quot;, &quot;obs3… #&gt; $ sampling_event_identifier &lt;chr&gt; &quot;S16201726&quot;, &quot;S21515362&quot;, &quot;S21431825&quot;, &quot;S44603056&quot;, &quot;S16508737&quot;, &quot;S16718542&quot;, &quot;S165… #&gt; $ protocol_type &lt;chr&gt; &quot;Traveling&quot;, &quot;Stationary&quot;, &quot;Traveling&quot;, &quot;Traveling&quot;, &quot;Stationary&quot;, &quot;Traveling&quot;, &quot;St… #&gt; $ protocol_code &lt;chr&gt; &quot;P22&quot;, &quot;P21&quot;, &quot;P22&quot;, &quot;P22&quot;, &quot;P21&quot;, &quot;P22&quot;, &quot;P21&quot;, &quot;P22&quot;, &quot;P22&quot;, &quot;P22&quot;, &quot;P21&quot;, &quot;P20&quot;,… #&gt; $ project_code &lt;chr&gt; &quot;EBIRD_MEX&quot;, &quot;EBIRD&quot;, &quot;EBIRD&quot;, &quot;EBIRD&quot;, &quot;EBIRD&quot;, &quot;EBIRD_MEX&quot;, &quot;EBIRD&quot;, &quot;EBIRD&quot;, &quot;EB… #&gt; $ duration_minutes &lt;int&gt; 90, 150, 120, 45, 30, 120, 5, 450, 105, 150, 5, NA, 3, 75, NA, 75, 30, 255, 140, 40… #&gt; $ effort_distance_km &lt;dbl&gt; 1.609, NA, 0.322, 0.322, NA, 2.000, NA, 40.234, 2.414, 2.000, NA, NA, NA, 3.000, NA… #&gt; $ effort_area_ha &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #&gt; $ number_observers &lt;int&gt; 4, 1, 1, 2, 2, 1, 1, 3, 13, 1, 1, 5, 5, 1, 4, 4, 1, 13, 1, 3, 4, 12, 3, 5, 2, 6, 9,… #&gt; $ all_species_reported &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,… #&gt; $ group_identifier &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #&gt; $ trip_comments &lt;chr&gt; &quot;RECORRIDO POR UNA HACIENDA.&quot;, &quot;from patio&quot;, NA, &quot;Bob and Prudy Bowers birded area … #&gt; $ scientific_name &lt;chr&gt; &quot;Phoenicopterus ruber&quot;, &quot;Phoenicopterus ruber&quot;, &quot;Phoenicopterus ruber&quot;, &quot;Phoenicopt… #&gt; $ observation_count &lt;chr&gt; &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;150&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;… #&gt; $ species_observed &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, … Notice that in addition to the observation_count column, we now have a binary species_observered column specifying whether or not the species was observered on this checklist. You can also automatically collapse the data by using the collapse = TRUE argument to auk_zerofill(). Exercise Zero-fill and collapse the Hooded Warbler data you extracted in the previous exercise. What proportion of checklists detected this species? Solution ebd_zf_hw &lt;- auk_zerofill(f_ebd_hw, f_sed_hw, collapse = TRUE) # proportion of checklists mean(ebd_zf_hw$species_observed) #&gt; [1] 0.268 Tip Whenever you’re zero-filling data it’s critical that you think about region and season (i.e. where and when) in addition to just the species. If you don’t do that, you’ll zero-fill the entire global EBD and your computer will explode! For example, consider a highly localized species like the Cozumel Vireo, endemic to the small island of Cozumel off the coast of Mexico. Let’s try just filtering on species. ebd_cozvir &lt;- auk_ebd(&quot;ebd_2014-2015_yucatan.txt&quot;, file_sampling = &quot;ebd_sampling_2014-2015_yucatan.txt&quot;) %&gt;% auk_species(&quot;Cozumel Vireo&quot;) %&gt;% auk_complete() %&gt;% auk_filter(&quot;data/ebd_cozvir.txt&quot;, &quot;data/sed_cozvir.txt&quot;) %&gt;% auk_zerofill(collapse = TRUE) table(ebd_cozvir$species_observed) #&gt; #&gt; FALSE TRUE #&gt; 22250 107 What we have here is the entire EBD (22 thousand checklists in the example dataset, and 40 million in the full EBD!) for a species that only occurs on one small island. Do we really care that a checklist in Anchorage, Alaska doesn’t have Cozumel Vireo? In this situation, you would be better to identify the boundaries of the island and use auk_bbox() to spatially subset the data. ebd_cozvir &lt;- auk_ebd(&quot;ebd_2014-2015_yucatan.txt&quot;, file_sampling = &quot;ebd_sampling_2014-2015_yucatan.txt&quot;) %&gt;% auk_species(&quot;Cozumel Vireo&quot;) %&gt;% # lng_min, lat_min, lng_max, lat_max auk_bbox(c(-87.1, 20.2, -86.7, 20.6)) %&gt;% auk_complete() %&gt;% auk_filter(&quot;data/ebd_cozvir.txt&quot;, &quot;data/sed_cozvir.txt&quot;, overwrite = TRUE) %&gt;% auk_zerofill(collapse = TRUE) table(ebd_cozvir$species_observed) #&gt; #&gt; FALSE TRUE #&gt; 433 107 We have the same number of positive observations, but have now drastically reduced the number of checklists that didn’t detect Cozumel Vireo observations. 6.3 Tidying up We now have a zero-filled presence-absence dataset with duplicate group checklists removed and all observations at the species level. There are couple remaining steps that we typically run to clean up the data. First, you may have noticed some cases where observation_count is &quot;X&quot; in the data. This is what eBirders enter for the count to indicate that they didn’t count the number of individuals for a given species. arrange(ebd_zf_df, desc(observation_count)) %&gt;% select(checklist_id, observation_count) %&gt;% head(10) #&gt; # A tibble: 10 x 2 #&gt; checklist_id observation_count #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 S26749776 X #&gt; 2 S16248765 X #&gt; 3 S16540721 X #&gt; 4 S16490447 X #&gt; 5 S16520714 X #&gt; 6 S16382176 X #&gt; # … with 4 more rows It’s more appropriate to have the count as NA rather than &quot;X&quot; in this scenario. This will also allow us to convert the count column to integer rather than character. At this point, we’ll also assign an explicit distance of 0 to stationary checklists. zf_count &lt;- ebd_zf_df %&gt;% mutate(observation_count = if_else(observation_count == &quot;X&quot;, NA_character_, observation_count), observation_count = as.integer(observation_count), effort_distance_km = if_else(protocol_type == &quot;Stationary&quot;, 0, effort_distance_km)) Finally, depending on your application, you’ll likely want to do some further filtering of the data. For many uses, it’s a good idea to reduce the variation in detectability between checklists by imposing some constraints on the effort variables. You can think of this as partially standardizing the observation process in a post hoc fashion. For example, in part II of this workshop, we’ll restrict observations to those from checklists less than 5 hours long and 5 km in length, and with 10 or fewer observers. zf_effort &lt;- zf_count %&gt;% filter(duration_minutes &lt;= 60 * 5, effort_distance_km &lt;= 5, number_observers &lt;= 10) table(zf_count$species_observed) #&gt; #&gt; FALSE TRUE #&gt; 244 47 table(zf_effort$species_observed) #&gt; #&gt; FALSE TRUE #&gt; 217 25 We’ve reduced the amount of data, but also decreased the variability in effort, which will lead to better model performance if we use these data to model species distributions. At this point, we can save the resulting processed eBird data, so that we can use it later in our analysis workflow. write_csv(zf_effort, &quot;data/ebird_amefla_zf.csv&quot;) "],
["subsampling.html", "Lesson 7 Spatiotemporal Subsampling 7.1 A toy example 7.2 Subsampling eBird data", " Lesson 7 Spatiotemporal Subsampling Despite the strengths of eBird data, species observations collected through citizen science projects present a number of challenges that are not found in conventional scientific data. In this chapter, we’ll discuss three of these challenges: spatial bias, temporal bias, and class imbalance. Spatial and temporal bias refers to the tendency of eBird checklists to be distributed non-randomly in space and time, while class imbalance refers to fact that there will be many more non-detections than detections for most species. All three can impact our ability to make reliable inferences from eBird data. Exercise Think of some examples of birder behavior that can lead to spatial and temporal bias. Solution Spatial bias: most eBirders sample near their homes, in easily accessible areas such as roadsides, or in areas and habitats of known high biodiversity. Temporal bias: eBirders preferentially sample when they are available, such as weekends, and at times of year when they expect to observe more birds, such as spring migration in North America. Fortunately, all three of these challenges can largely be addressed by spatiotemporal subsampling of the eBird data prior to modeling. In particular, this consists of dividing space and time up into a regular grid (e.g. 5 km x 5 km x 1 week), and only selecting a subset of checklists from each grid cell. To deal with class imbalance, we can subsample detections and non-detections separately to ensure we don’t lose too many detections. For the spatial part of the subsampling we’ll use the package dggridR to generate a regular hexagonal grid and assign points to the cells of this grid. Hexagonal grids are preferable to square grids because they exhibit significantly less spatial distortion. 7.1 A toy example To illustrate how spatial sampling on a hexagonal grid works, let’s start with a simpe toy example. We’ll generate 500 randomly placed points, construct a hexagonal grid with 5 km spacing, assign each point to a grid cell, then select a single point within each cell. library(auk) library(sf) library(dggridR) library(lubridate) library(tidyverse) # bounding box to generate points from bb &lt;- st_bbox(c(xmin = -0.1, xmax = 0.1, ymin = -0.1, ymax = 0.1), crs = 4326) %&gt;% st_as_sfc() %&gt;% st_sf() # random points pts &lt;- st_sample(bb, 500) %&gt;% st_sf(as.data.frame(st_coordinates(.)), geometry = .) %&gt;% rename(lat = Y, lon = X) # contruct a hexagonal grid with ~ 5 km between cells dggs &lt;- dgconstruct(spacing = 5) #&gt; Resolution: 13, Area (km^2): 31.9926151554038, Spacing (km): 5.58632116604266, CLS (km): 6.38233997895802 # for each point, get the grid cell pts$cell &lt;- dgGEO_to_SEQNUM(dggs, pts$lon, pts$lat)$seqnum # sample one checklist per grid cell pts_ss &lt;- pts %&gt;% group_by(cell) %&gt;% sample_n(size = 1) %&gt;% ungroup() # generate polygons for the grid cells hexagons &lt;- dgcellstogrid(dggs, unique(pts$cell), frame = FALSE) %&gt;% st_as_sf() ggplot() + geom_sf(data = hexagons) + geom_sf(data = pts, size = 0.5) + geom_sf(data = pts_ss, col = &quot;red&quot;) + theme_bw() In the above plot, black dots represent the original set of 500 randomly placed points, while red dots represent the subsampled data, one point per hexagonal cell. 7.2 Subsampling eBird data Now let’s apply this same approach to the zero-filled American Flamingo data we produced in the previous lesson; however, now we’ll temporally sample as well, at a resolution of one week, and sample presences and absences separately. We start by reading in the eBird data and assigning each checklist to a hexagonal grid cell and a week. # generate hexagonal grid with ~ 5 km betweeen cells dggs &lt;- dgconstruct(spacing = 5) #&gt; Resolution: 13, Area (km^2): 31.9926151554038, Spacing (km): 5.58632116604266, CLS (km): 6.38233997895802 # read in data ebird &lt;- read_csv(&quot;data/ebird_amefla_zf.csv&quot;) %&gt;% # get hexagonal cell id and week number for each checklist mutate(cell = dgGEO_to_SEQNUM(dggs, longitude, latitude)$seqnum, year = year(observation_date), week = week(observation_date)) Now we sample a single checklist from each grid cell for each week, using group_by() to sample presences and absences separetely. ebird_ss &lt;- ebird %&gt;% group_by(species_observed, year, week, cell) %&gt;% sample_n(size = 1) %&gt;% ungroup() Exercise How did the spatiotemporal subsampling affect the overall sample size as well as the prevalence of detections? Solution # original data nrow(ebird) #&gt; [1] 242 count(ebird, species_observed) %&gt;% mutate(percent = n / sum(n)) #&gt; # A tibble: 2 x 3 #&gt; species_observed n percent #&gt; &lt;lgl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 FALSE 217 0.897 #&gt; 2 TRUE 25 0.103 # after sampling nrow(ebird_ss) #&gt; [1] 147 count(ebird_ss, species_observed) %&gt;% mutate(percent = n / sum(n)) #&gt; # A tibble: 2 x 3 #&gt; species_observed n percent #&gt; &lt;lgl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 FALSE 126 0.857 #&gt; 2 TRUE 21 0.143 So, the subsampling decreased the overall number of checklists from 242 to 147, but increased the prevalence of detections from 10% to 14%. "],
["applications.html", "Lesson 8 Applications 8.1 Frequency trajectories 8.2 Maps", " Lesson 8 Applications Now that we know how to extract and zero-fill data from eBird, let’s do something with these data! We’ll start by summarizing the data to show the trajectory of observation frequency over the course of the year. Next, we’ll make a basic presence-absence map of eBird observations. More advanced topics are covered in part II of this workshop, which focuses on using eBird data to model species distributions. We’ll start a new script for this lesson: 02_applications.R. 8.1 Frequency trajectories The genus Cardellina contains five New World warbler species, including some of the most spectacular birds in North America: Canada Warbler, Red Warbler, and Pink-headed Warbler. Let’s extract and zero-fill data for three of the species in this genus within Guatemala. library(auk) library(sf) library(rnaturalearth) library(lubridate) library(tidyverse) f_ebd &lt;- &quot;data/ebd_cardellina.txt&quot; f_sed &lt;- &quot;data/sed_cardellina.txt&quot; # extract filters &lt;- auk_ebd(&quot;ebd_2014-2015_yucatan.txt&quot;, file_sampling = &quot;ebd_sampling_2014-2015_yucatan.txt&quot;) %&gt;% auk_species(c(&quot;Canada Warbler&quot;, &quot;Wilson&#39;s Warbler&quot;, &quot;Pink-headed Warbler&quot;)) %&gt;% auk_country(&quot;Guatemala&quot;) %&gt;% auk_complete() %&gt;% auk_filter(f_ebd, f_sed) # zero-fill cardellina_zf &lt;- auk_zerofill(f_ebd, f_sed, collapse = TRUE) count(cardellina_zf, scientific_name, species_observed) #&gt; # A tibble: 6 x 3 #&gt; scientific_name species_observed n #&gt; &lt;chr&gt; &lt;lgl&gt; &lt;int&gt; #&gt; 1 Cardellina canadensis FALSE 6454 #&gt; 2 Cardellina canadensis TRUE 54 #&gt; 3 Cardellina pusilla FALSE 4795 #&gt; 4 Cardellina pusilla TRUE 1713 #&gt; 5 Cardellina versicolor FALSE 6322 #&gt; 6 Cardellina versicolor TRUE 186 Next, let’s summarize these data, calculating the frequency of observation on eBird checklists by month. cardellina_freq &lt;- cardellina_zf %&gt;% mutate(month = month(observation_date)) %&gt;% group_by(scientific_name, month) %&gt;% summarize(obs_freq = mean(species_observed)) %&gt;% ungroup() In preparation for plotting, we can add the common names of the species by joining in the ebird_taxonomy data frame, which is included with auk. In addition, we’ll convert the integer month numbers to dates–using the midpoint of each month–to aid axis labeling. cardellina_comm &lt;- cardellina_freq %&gt;% inner_join(ebird_taxonomy, by = &quot;scientific_name&quot;) %&gt;% select(common_name, month, obs_freq) %&gt;% mutate(month_midpoint = ymd(str_glue(&quot;2019-{month}-15&quot;))) Finally, let’s make a frequency trajectory for these four species. ggplot(cardellina_comm) + aes(x = month_midpoint, y = obs_freq, color = common_name) + geom_point() + geom_line() + scale_x_date(date_breaks = &quot;2 months&quot;, date_labels = &quot;%b&quot;) + scale_color_brewer(palette = &quot;Set1&quot;) + labs(x = &quot;Month&quot;, y = &quot;Observation Frequency&quot;, color = NULL) + theme(legend.position = &quot;bottom&quot;) We have several different patterns going on here: Pink-headed Warblers is a resident species, present year-round at fairly low abundance Wilson’s Warbler spends the winter in Guatemala and is common during that period Canada Warbler appears to only pass through Guatemala during migration 8.2 Maps Continuing with the same dataset, let’s make a presence-absence map for Pink-headed Warbler. We’ll start by filtering the zero-filled data to only Pink-headed Warbler observations and converting these points to a spatial format using the sf package. pihwar &lt;- cardellina_zf %&gt;% filter(scientific_name == &quot;Cardellina versicolor&quot;) %&gt;% st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) Next, we’ll use rnaturalearth to get some contextual GIS data to use in our maps. This is an amazing source for free GIS data for making maps. ne_country &lt;- ne_countries(continent = &quot;North America&quot;, returnclass = &quot;sf&quot;) %&gt;% st_geometry() ne_gt &lt;- ne_countries(country = &quot;Guatemala&quot;, returnclass = &quot;sf&quot;) %&gt;% st_geometry() # restrict to points falling within Guatemala, removes those over water pihwar &lt;- pihwar[ne_gt, ] Finally, we’ll make a presence-absence map, building it up in layers. There are lots excellent tools for mapping in R; however, here we’ll use the basic plot() function from the sf package. Other good options include ggplot2 and tmap. par(mar = c(0.25, 0.25, 0.25, 0.25)) # start by defining the bounds of the map with an empty plot plot(ne_gt, col = NA, border = NA) # borders plot(ne_country, col = &quot;grey80&quot;, border = &quot;white&quot;, add = TRUE) plot(ne_gt, col = &quot;grey70&quot;, border = &quot;white&quot;, add = TRUE) # not observed pihwar_abs &lt;- filter(pihwar, !species_observed) %&gt;% st_geometry() plot(pihwar_abs, col = alpha(&quot;grey20&quot;, 0.3), pch = 19, cex = 0.25, add = TRUE) # present pihwar_pres &lt;- filter(pihwar, species_observed) %&gt;% st_geometry() plot(pihwar_pres, col = alpha(&quot;orange&quot;, 1), pch = 19, cex = 0.5, add = TRUE) title(&quot;Pink-headed Warbler eBird Observations&quot;, line = -1) legend(&quot;bottomright&quot;, col = c(&quot;grey20&quot;, &quot;orange&quot;), legend = c(&quot;Not reported&quot;, &quot;Present&quot;), pch = 19) box() Based on this map, we see that Pink-headed Warbler is restricted to the southwestern highlands of Guatemala. Exercise Make a similar map of Wilson’s Warbler (Cardellina pusilla) observations. Solution # prepare data wilwar &lt;- cardellina_zf %&gt;% filter(scientific_name == &quot;Cardellina pusilla&quot;) %&gt;% mutate(pres_abs = if_else(species_observed, &quot;Present&quot;, &quot;Not detected&quot;)) %&gt;% st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) wilwar &lt;- wilwar[ne_gt, ] # make map par(mar = c(0.25, 0.25, 0.25, 0.25)) plot(ne_gt, col = NA, border = NA) plot(ne_country, col = &quot;grey80&quot;, border = &quot;white&quot;, add = TRUE) plot(ne_gt, col = &quot;grey70&quot;, border = &quot;white&quot;, add = TRUE) # not observed wilwar_abs &lt;- filter(wilwar, !species_observed) %&gt;% st_geometry() plot(wilwar_abs, col = alpha(&quot;grey20&quot;, 0.3), pch = 19, cex = 0.25, add = TRUE) # present wilwar_pres &lt;- filter(wilwar, species_observed) %&gt;% st_geometry() plot(wilwar_pres, col = alpha(&quot;orange&quot;, 1), pch = 19, cex = 0.5, add = TRUE) title(&quot;Wilson&#39;s Warbler eBird Observations&quot;, line = -1) legend(&quot;bottomright&quot;, col = c(&quot;grey20&quot;, &quot;orange&quot;), legend = c(&quot;Not reported&quot;, &quot;Present&quot;), pch = 19) box() "],
["model-intro.html", "Lesson 9 Introduction 9.1 Example data", " Lesson 9 Introduction In Part I of this workshop, we saw that eBird provides a wealth of open access bird observation data. The sheer volume of data, combined with the broad spatial, temporal, and taxonomic coverage, make the eBird database a valuable resource for answering a variety of ecological questions. Furthermore, eBird data have two key characteristics that distinguish it from many other citizen science projects and facilitate robust ecological analyses: the complete checklists allow non-detection to be inferred and the effort information associated with a checklist facilitates robust analyses by accounting for variation in the observation process. Despite the strengths of eBird data, species observations collected through citizen science projects present a number of challenges that are not found in conventional scientific data. The following are some of the primary challenges associated these data; challenges that will be addressed in the following lessons: Taxonomic bias: eBirders often have preferences for certain species, which may lead to preferential recording of some species over others. Restricting analyses to complete checklists largely mitigates this issue. Spatial and temporal bias: eBird data are not randomly distributed in space and time. Most eBirders submit data from times and places that are convenient (e.g. near roads or on weekends) or likely to produce checklists with high biodiversity (e.g. in good habitats, during migration, or early in the morning). Spatiotemporal subsampling, covered in Part I of this workshop, can reduce the impact of spatial and temporal bias. Class imbalance: bird species that are rare or hard to detect may have data with high class imbalance, with many more checklists with non-detections than detections. For these species, a distribution model predicting that the species is absent everywhere will have high accuracy, but no ecological value. Subsampling detections and non-detections independently can be used to address class imbalance. Spatial precision: the spatial location of an eBird checklist is given as a single latitude-longitude point; however, this may not be precise for two main reasons. First, for traveling checklists, this location represents just one point on the journey. Second, eBird checklists are often assigned to a hotspot (a common location for all birders visiting a popular birding site) rather than their true location. Filtering eBird data to checklists below a given length (e.g. less than 5 km), and summarizing covariates within a neighborhood around the checklist location, will reduce the impact of spatial imprecision. Variation in detectability: detectability describes the probability of a species that is present in an area being detected and identified. It varies by season, habitat, and species. Furthermore, eBird data are collected with high variation in effort, time of day, number of observers, and external conditions such as weather, all of which can affect the detectability of specie. Therefore, detectability is particularly important to consider when predictions are compared between seasons, habitats or species. Since eBird uses a semi-structured protocol, that collects variables associated with variation in detectability, we’ll be able to account for a larger proportion of this variation in our analyses. The following three lessons will focus on modeling patterns of bird distribution and abundance using eBird data. We won’t delve too deeply into the technical details of these models, rather we’ll focus on demonstrating a set of best practices for distribution modeling that address the specific challenges associated with eBird data. The three types of models that we’ll cover are: Encounter rate: expected rate of an average eBirder encountering a species while traveling 1km, 1 hour, at the optimal time of day. Occupancy: probability that a site hosts one or more individuals of a species. In this model, detection is explicitly estimated. Relative abundance: expected count of a species by an average eBirder while traveling 1km, 1 hour, at the optimal time of day. Both encounter rate and relative abundance will be modeled using a machine learning approach, where the focus is primarily on prediction. In contrast, occupancy modeling is a more traditional likelihood approach, where the focus is on inference and trying to understand the process that generated the data. Machine learning has the additional benefit that it can learn complex, non-linear relationships between the response and predictor variables, while occupancy models are typically constrained to linear effect and simple interactions. 9.1 Example data For all the examples in the following lessons, we’ll focus on modeling Wood Thrush in June in Bird Conservation Region (BCR) 27 (Southeastern Coastal Plain). To prepare data for these lessons, we extracted complete traveling and stationary eBird checklists from the past 10 years and zero-filled them to produce presence-absence data following the methods outlined in Part I of this workshop. In addition, to reduce the variation in detectability between checklists, we restricted checklists to less than 5 hours long and 5 km in length, and with 10 or fewer observers. Finally, we processed remotely sensed land cover and elevation data to be used as covariates for modeling. Specifically, within a 2.5 km neighborhood around each checklist, we used the MODIS MCD12Q1 land cover product to calculate the percentage of 16 different land cover classes and a global elevation dataset to calculate the mean and standard deviation of elevation. The workshop data package discussed in the Introduction contains all the prepared data. If you haven’t already done so, download and unzip this file, then move all the files in the data/ subdirectory to the data/ subdirectory of your RStudio project. The following map shows the study area and eBird checklists that we’ll use. The code used to generate these data is available in the eBird Best Practices book associated with this workshop. Consult the chapter on eBird Data for details on the eBird data extraction and the chapter on habitat covariates for details on preparing the land cover and elevation data. "],
["encounter.html", "Lesson 10 Encounter Rate 10.1 Data preparation 10.2 Random forests 10.3 Habitat associations 10.4 Prediction 10.5 Exercises", " Lesson 10 Encounter Rate In this lesson, we’ll estimate the encounter rate of Wood Thrush on eBird checklists in June in BCR 27, where encounter rate is defined as the probability of an eBirder encountering a species on a standard eBird checklist. We’ll be using random forests in this lesson, a machine learning technique that uses an ensemble of many decision trees, each of which is fit using a bootstrap sampled of the data. For the purposes of this tutorial, we’ll treat the random forest as a black box method. Let’s start by loading all the packages and data we’ll need for this lesson. library(sf) library(raster) library(dggridR) library(lubridate) library(ranger) library(scam) library(PresenceAbsence) library(verification) library(edarf) library(ebirdst) library(fields) library(gridExtra) library(tidyverse) # resolve namespace conflicts select &lt;- dplyr::select projection &lt;- raster::projection map &lt;- purrr::map set.seed(1) # ebird data ebird &lt;- read_csv(&quot;data/ebd_woothr_june_bcr27_zf.csv&quot;) %&gt;% # year required to join to habitat data mutate(year = year(observation_date)) # modis habitat covariates habitat &lt;- read_csv(&quot;data/pland-elev_location-year.csv&quot;) %&gt;% mutate(year = as.integer(year)) # combine ebird and habitat data ebird_habitat &lt;- inner_join(ebird, habitat, by = c(&quot;locality_id&quot;, &quot;year&quot;)) # prediction surface pred_surface &lt;- read_csv(&quot;data/pland-elev_prediction-surface.csv&quot;) r &lt;- raster(&quot;data/prediction-surface.tif&quot;) # load gis data for making maps map_proj &lt;- st_crs(102003) ne_land &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_land&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() bcr &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;bcr&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() ne_country_lines &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_country_lines&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() ne_state_lines &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_state_lines&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() 10.1 Data preparation As we learned in Part I of this workshop, spatiotemporal subsampling can reduce spatial and temporal bias, and class imbalance, provided we sample detections and non-detections separately. So, we’ll apply subsampling prior to fitting the random forest model. Tip Sampling detections and non-detections separately will change the prevalence rate of the detections in the data. As a result, the estimated probability of occurrence based on these subsampled data will be larger than the true occurrence rate. When examining the outputs from the models it will be important to recall that we altered the prevalence rate at this stage. # generate hexagonal grid with ~ 5 km betweeen cells dggs &lt;- dgconstruct(spacing = 5) #&gt; Resolution: 13, Area (km^2): 31.9926151554038, Spacing (km): 5.58632116604266, CLS (km): 6.38233997895802 # get hexagonal cell id and week number for each checklist checklist_cell &lt;- ebird_habitat %&gt;% mutate(cell = dgGEO_to_SEQNUM(dggs, longitude, latitude)$seqnum, year = year(observation_date), week = week(observation_date)) # sample one checklist per grid cell per week # sample detection/non-detection independently ebird_ss &lt;- checklist_cell %&gt;% group_by(species_observed, year, week, cell) %&gt;% sample_n(size = 1) %&gt;% ungroup() Tip For very rare species, a more drastic approach to dealing with class imbalance is needed: only subsampling the non-detections and keeping all the detections. Here’s one way of accomplishing this. split_det &lt;- split(checklist_cell, checklist_cell$species_observed) ebird_all_det &lt;- split_det$`FALSE` %&gt;% group_by(year, week, cell) %&gt;% sample_n(size = 1) %&gt;% ungroup() %&gt;% bind_rows(split_det$`TRUE`) This approach leads to many more detections being kept in the data. sum(ebird_ss$species_observed) #&gt; [1] 1425 sum(ebird_all_det$species_observed) #&gt; [1] 2013 However, some of the extra detections we have with this approach are in the same 5km cell and the same week, they may not be independent. There are trade-offs to many of these decisions about post-hoc sampling. In preparation for modeling, we’ll select only the the columns that will be used as predictors in the model. We include both habitat predictors, which we expect to influence whether a species is present at a site, and also effort predictors to help control for variation in detectability. # select covariates for model ebird_ss &lt;- ebird_ss %&gt;% select(species_observed, year, day_of_year, time_observations_started, duration_minutes, effort_distance_km, number_observers, starts_with(&quot;pland_&quot;), starts_with(&quot;elevation_&quot;)) %&gt;% drop_na() Finally, we’ll hold 20% of the data aside so we have an independent test set, which we can later use to assess the performance of our model. # split 80/20 ebird_split &lt;- ebird_ss %&gt;% split(if_else(runif(nrow(.)) &lt;= 0.8, &quot;train&quot;, &quot;test&quot;)) Exercise How would you modify the above code to include 25% of data in the test set? Solution ebird_split_25 &lt;- ebird_ss %&gt;% split(if_else(runif(nrow(.)) &lt;= 0.75, &quot;train&quot;, &quot;test&quot;)) 10.2 Random forests Random forests are an excellent, general purpose machine learning method suitable for modeling encounter rate in a wide variety of scenarios. To address the issue of class imbalance, we’ll use a balanced random forest approach, a modification of the traditional random forest algorithm specifically designed to handle scenarios in which one class (in our case: species detections) is much more common than the other (non-detections). To implement a balanced random forest, we’ll first need to calculate the frequency of detections (the smaller class). detection_freq &lt;- mean(ebird_split$train$species_observed) Now we can use the ranger package to fit a random forest model to the eBird data. # ranger requires a factor response to do classification ebird_split$train$species_observed &lt;- factor(ebird_split$train$species_observed) # grow random forest rf &lt;- ranger(formula = species_observed ~ ., data = ebird_split$train, importance = &quot;impurity&quot;, probability = TRUE, replace = TRUE, sample.fraction = c(detection_freq, detection_freq)) 10.2.1 Model assessment To assess model quality, we’ll validate the model’s ability to predict the observed patterns of occurrence using independent validation data (i.e. the 20% test data set that we removed earlier). We’ll use a range of predictive performance metrics to compare the predictions to the actual observations. Different performance metrics reveal different aspects of the data and we can choose to emphasise some over others, depending on the specific goals of our analysis. For example, if we want to minimise the number of false negatives (i.e. we don’t want to miss any places where the species actually occurs), we would focus on sensitivity. # predict on test data preds &lt;- predict(rf, data = ebird_split$test, type = &quot;response&quot;) # extract probability of detection preds &lt;- preds$predictions[, 2] rf_pred_test &lt;- data.frame(id = seq_along(preds), # actual detection/non-detection obs = ebird_split$test$species_observed, # predictions pred = preds) %&gt;% drop_na() # mean squared error (mse) mse &lt;- mean((rf_pred_test$obs - rf_pred_test$pred)^2, na.rm = TRUE) # pick threshold to maximize kappa opt_thresh &lt;- optimal.thresholds(rf_pred_test, opt.methods = &quot;MaxKappa&quot;) # calculate accuracy metrics: auc, kappa, sensitivity, specificity, brier pa_metrics &lt;- presence.absence.accuracy(rf_pred_test, threshold = opt_thresh$pred, na.rm = TRUE, st.dev = FALSE) # combine various performance metrics together rf_assessment &lt;- tibble( metric = c(&quot;mse&quot;, &quot;sensitivity&quot;, &quot;specificity&quot;, &quot;auc&quot;, &quot;kappa&quot;), value = c(mse, pa_metrics$sensitivity, pa_metrics$specificity, pa_metrics$AUC, pa_metrics$Kappa) ) knitr::kable(rf_assessment, digits = 3) metric value mse 0.135 sensitivity 0.485 specificity 0.927 auc 0.852 kappa 0.337 10.3 Habitat associations From the random forest model, we can glean two important sources of information about the association between Wood Thrush detection and features of their local environment. First, predictor importance is a measure of the predictive power of each covariate, and is calculated as a byproduct of fitting a random forest model. Second, partial dependence plots estimate the marginal effect of one predictor holding all other predictors constant. 10.3.1 Predictor importance During the process of fitting a random forest model, some variables are removed at each node of the trees that make up the random forest. Predictor importance is based on the mean decrease in accuracy of the model when a given covariate is not used. pi &lt;- enframe(rf$variable.importance, &quot;predictor&quot;, &quot;importance&quot;) # plots ggplot(pi) + aes(x = fct_reorder(predictor, importance), y = importance) + geom_col() + geom_hline(yintercept = 0, size = 2, colour = &quot;#555555&quot;) + scale_y_continuous(expand = c(0, 0)) + coord_flip() + labs(x = NULL, y = &quot;Predictor Importance (Gini Index)&quot;) + theme_minimal() + theme(panel.grid = element_blank(), panel.grid.major.x = element_line(colour = &quot;#cccccc&quot;, size = 0.5)) Tip Consult the file data/mcd12q1_classes.csv for a key to the different pland_ variables. class name —— ———————————— 0 Water bodies 1 Evergreen Needleleaf Forests 2 Evergreen Broadleaf Forests 3 Deciduous Needleleaf Forests 4 Deciduous Broadleaf Forests 5 Mixed Forests 6 Closed Shrublands 7 Open Shrublands 8 Woody Savannas 9 Savannas 10 Grasslands 11 Permanent Wetlands 12 Croplands 13 Urban and Built-up Lands 14 Cropland/Natural Vegetation Mosaics 15 Non-Vegetated Lands 255 Unclassified 10.3.2 Partial dependence Partial dependence plots show the marginal effect of a given predictor on encounter rate averaged across the other predictors. We’ll use the R package edarf to construct partial dependence plots for the most important predictors. # top 9 predictors other than date top_pred &lt;- pi %&gt;% filter(!predictor %in% c(&quot;year&quot;, &quot;day_of_year&quot;)) %&gt;% top_n(n = 9, wt = importance) %&gt;% arrange(desc(importance)) # calculate partial dependence for each predictor pd &lt;- top_pred %&gt;% mutate(pd = map(predictor, partial_dependence, fit = rf, data = ebird_split$train), pd = map(pd, ~ .[, c(1, 3)]), pd = map(pd, set_names, nm = c(&quot;value&quot;, &quot;encounter_rate&quot;))) %&gt;% unnest(cols = pd) # plot ggplot(pd) + aes(x = value, y = encounter_rate) + geom_line() + geom_point() + scale_y_continuous(labels = scales::percent) + facet_wrap(~ as_factor(predictor), nrow = 3, scales = &quot;free&quot;) + labs(x = NULL, y = &quot;Encounter Rate&quot;) + theme_minimal() + theme_minimal() + theme(panel.grid = element_blank(), axis.line = element_line(color = &quot;grey60&quot;), axis.ticks = element_line(color = &quot;grey60&quot;)) 10.4 Prediction Finally, we can use the random forest model to make a map of Wood Thrush encounter rate in BCR 27! The data package contains a prediction surface consisting of the PLAND habitat covariates summarized on a regular grid of points across BCR 27. We’ll make predictions of encounter rate at these points. However, first we need to bring effort variables into this prediction surface. We’ll make predictions for a standard eBird checklist: a 1 km, 1 hour traveling count at the peak time of day for detecting this species. To find the time of day with the highest detection probability, we can look for the peak of the partial dependence plot, constraining the search to times of day for which there are enough data to make reasonable predictions (hours with at least 1% of checklists). # find peak time of day from partial dependence pd_time &lt;- partial_dependence(rf, vars = &quot;time_observations_started&quot;, # make estimates at 30 minute intervals # use the entire training dataset for estimation n = c(24 * 2, nrow(ebird_split$train)), data = ebird_split$train) %&gt;% select(time_observations_started, encounter_rate = &quot;TRUE&quot;) # hours with at least 1% of checklists search_hours &lt;- ebird_split$train %&gt;% mutate(hour = floor(time_observations_started)) %&gt;% count(hour) %&gt;% mutate(pct = n / sum(n)) %&gt;% filter(pct &gt;= 0.01) # constrained peak time t_peak &lt;- pd_time %&gt;% filter(floor(time_observations_started) %in% search_hours$hour) %&gt;% top_n(1, wt = desc(time_observations_started)) %&gt;% pull(time_observations_started) t_peak #&gt; [1] 5.08 Based on this analysis, the best time for detecting Wood Thrush is at 5:05 AM. Now we can use this time to make predictions. # add effort covariates to prediction pred_surface_eff &lt;- pred_surface %&gt;% mutate(observation_date = ymd(&quot;2018-06-15&quot;), year = year(observation_date), day_of_year = yday(observation_date), time_observations_started = t_peak, duration_minutes = 60, effort_distance_km = 1, number_observers = 1) # predict pred_rf &lt;- predict(rf, data = pred_surface_eff, type = &quot;response&quot;) pred_rf &lt;- pred_rf$predictions[, 2] # add to prediction surface pred_er &lt;- bind_cols(pred_surface_eff, encounter_rate = pred_rf) %&gt;% select(latitude, longitude, encounter_rate) %&gt;% mutate(encounter_rate = pmin(pmax(encounter_rate, 0), 1)) Next, we’ll convert this data frame to spatial features using sf, then rasterize the points using the prediction surface raster template. # rasterize predictions r_pred &lt;- pred_er %&gt;% # convert to spatial features st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) %&gt;% st_transform(crs = projection(r)) %&gt;% # rasterize rasterize(r) r_pred &lt;- r_pred[[-1]] Finally, we can map these predictions! # project predictions r_pred_proj &lt;- projectRaster(r_pred, crs = map_proj$proj4string, method = &quot;ngb&quot;) par(mar = c(3.5, 0.25, 0.25, 0.25)) # set up plot area plot(bcr, col = NA, border = NA) plot(ne_land, col = &quot;#dddddd&quot;, border = &quot;#888888&quot;, lwd = 0.5, add = TRUE) # encounter rate r_max &lt;- ceiling(10 * cellStats(r_pred_proj, max)) / 10 brks &lt;- seq(0, r_max, by = 0.025) lbl_brks &lt;- seq(0, r_max, by = 0.1) # ebird status and trends color palette pal &lt;- abundance_palette(length(brks) - 1) plot(r_pred_proj, col = pal, breaks = brks, maxpixels = ncell(r_pred_proj), legend = FALSE, add = TRUE) # borders plot(bcr, border = &quot;#000000&quot;, col = NA, lwd = 1, add = TRUE) plot(ne_state_lines, col = &quot;#ffffff&quot;, lwd = 0.75, add = TRUE) plot(ne_country_lines, col = &quot;#ffffff&quot;, lwd = 1.5, add = TRUE) box() # legend par(new = TRUE, mar = c(0, 0, 0, 0)) title &lt;- &quot;Wood Thrush Encounter Rate&quot; image.plot(zlim = range(brks), legend.only = TRUE, col = pal, breaks = brks, smallplot = c(0.25, 0.75, 0.06, 0.09), horizontal = TRUE, axis.args = list(at = lbl_brks, labels = lbl_brks, fg = &quot;black&quot;, col.axis = &quot;black&quot;, cex.axis = 0.75, lwd.ticks = 0.5, padj = -1.5), legend.args = list(text = title, side = 3, col = &quot;black&quot;, cex = 1, line = 0)) 10.5 Exercises Now that you’ve completed this lesson, try modifying your script to complete at least one of the following exercises: How does changing the subsampling grid cell size affect the model performance? What happens to the predictions if you make them for an eBirder traveling further than 1 km, or birding for longer than 1 hour? Filter the data to only shorter duration checklists or shorter distances traveled. How does this affect model performance? An alternative approach to dealing with class imbalance, is to grid sample only the non-detections, while keeping all the detections. Try this subsampling approach and see what the affect is on the predictive performance metrics. "],
["occupancy.html", "Lesson 11 Occupancy 11.1 Data preparation 11.2 Occupancy modeling 11.3 Prediction 11.4 Exercises", " Lesson 11 Occupancy In this lesson, we’ll use occupancy models to estimate the occupancy of Wood Thrush on eBird checklists in June in BCR 27, while explicitly accounting for imperfect detection. First, we’ll give a short presentation introducing occupancy modeling. The presentation can be downloaded in PowerPoint or PDF format, or viewed on SpeakerDeck. Let’s start by loading the packages and data required for this lesson. library(auk) library(lubridate) library(sf) library(dggridR) library(unmarked) library(raster) library(ebirdst) library(MuMIn) library(AICcmodavg) library(fields) library(tidyverse) # resolve namespace conflicts select &lt;- dplyr::select projection &lt;- raster::projection set.seed(1) # ebird data ebird &lt;- read_csv(&quot;data/ebd_woothr_june_bcr27_zf.csv&quot;) %&gt;% mutate(year = year(observation_date), # occupancy modeling requires an integer response species_observed = as.integer(species_observed)) # modis land cover covariates habitat &lt;- read_csv(&quot;data/pland-elev_location-year.csv&quot;) %&gt;% mutate(year = as.integer(year)) # combine ebird and modis data ebird_habitat &lt;- inner_join(ebird, habitat, by = c(&quot;locality_id&quot;, &quot;year&quot;)) # prediction surface pred_surface &lt;- read_csv(&quot;data/pland-elev_prediction-surface.csv&quot;) # latest year of landcover data max_lc_year &lt;- pred_surface$year[1] r &lt;- raster(&quot;data/prediction-surface.tif&quot;) # load gis data for making maps map_proj &lt;- st_crs(102003) ne_land &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_land&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() bcr &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;bcr&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() ne_country_lines &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_country_lines&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() ne_state_lines &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_state_lines&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() 11.1 Data preparation Since we’ll be fitting a single-season occupancy models, we’ll need to start by focusing on observations from June of a single year, in this case the most recent year for which we have data. At this point, we also suggest subsetting the data to observations with 5 or fewer observers since there are few checklists with more than 5 observers. # filter to a single year of data ebird_filtered &lt;- filter(ebird_habitat, number_observers &lt;= 5, year == max(year)) Next, we need to extract a subset of observations that are suitable for occupancy modeling. In particular, occupancy models typically require data from repeated visits to a single site during a time frame over which the population can be considered closed. The auk function filter_repeat_visits() is designed to extract subsets of eBird data that meet these criteria. Specifically, we want repeat visits to the same location by the same observer, so we’ll use latitude, longitude, and observer ID to define ‘sites’. We’ll take the month of June as our period of closure.The relevant parameters in filter_repeat_visits are: min_obs and max_obs: the minimum and maximum number of repeat visits to a given site. Occupancy modeling requires at least two visits to each site. date_var: the column name of the date variable used to define the period of closure. annual_closure: define the period of closure as the entire year. This works here because we’ve already subset the data to only keep observations from January, which results in the period of closure being the month of January in given year. The n_days argument can be used to define the period of closure more flexibly. site_vars: a character vector of names of columns that define a site. This is typically the combination of variables defining the location (locality_id or latitude/longitude) and observer (observer_id). # subset for occupancy modeling occ &lt;- filter_repeat_visits(ebird_filtered, min_obs = 2, max_obs = 10, annual_closure = TRUE, date_var = &quot;observation_date&quot;, site_vars = c(&quot;locality_id&quot;, &quot;observer_id&quot;)) Three new columns are added to the dataset when using the function filter_repeat_visits(): site is a unique site ID, closure_id identifies the primary period of closure (in this example the year), and n_observations is the number of visits to each site. select(occ, site, closure_id, n_observations) #&gt; # A tibble: 3,656 x 3 #&gt; site closure_id n_observations #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 L1005433_obs119886_2019 2019 3 #&gt; 2 L1005433_obs119886_2019 2019 3 #&gt; 3 L1005433_obs119886_2019 2019 3 #&gt; 4 L1007991_obs132896_2019 2019 2 #&gt; 5 L1007991_obs132896_2019 2019 2 #&gt; 6 L1007991_obs970026_2019 2019 3 #&gt; # … with 3,650 more rows Exercise Suppose you define the temporal period of closure as week long blocks, rather than the whole month of June. Use filter_repeat_visits() to extract eBird data accordingly. Consult the documentation for this function for help. Solution occ_days &lt;- filter_repeat_visits(ebird_filtered, min_obs = 2, max_obs = 10, n_days = 7, date_var = &quot;observation_date&quot;, site_vars = c(&quot;latitude&quot;, &quot;longitude&quot;, &quot;observer_id&quot;)) Exercise Subsetting eBird data to just the observations suitable for occupancy modeling will inevitably reduce the amount of data. What proportion of observations remain after calling filter_repeat_visits()? How many unique sites do we have? Solution nrow(occ) / nrow(ebird_habitat) #&gt; [1] 0.0768 n_distinct(occ$site) #&gt; [1] 966 Now that we have data suitable for occupancy modeling, we need to reformat the data to be accepted by unmarked. The documentation for the unmarked function formatWide() outlines the details of this format. In the EBD, each row is a checklist; however, unmarked requires each row to be a site with the first column specifying the site ID and subsequent columns specifying whether the species was observed on each of the visits to that site. The next group of columns contains site-level covariates, those that vary between sites but are constant across visits to the same site, such as latitude, longitude, and any habitat covariates we might have. Finally, the observation-level covariates, such as distance and duration, each get a set of columns corresponding to the the presence-absence columns. Here’s a simple example with some made up data to illustrate the format: site_id y.1 y.2 y.3 latitude longitude forest_cover distance.1 distance.2 distance.3 time.1 time.2 time.3 site1 TRUE FALSE TRUE 20.2 182 0.12 14.51 10.01 12.41 33.7 43.5 20.7 site2 FALSE TRUE 20.6 183 0.45 9.84 11.90 26.4 23.8 site3 TRUE FALSE FALSE 19.9 182 0.98 8.95 12.63 9.78 23.4 30.1 13.3 site4 TRUE FALSE 21.0 183 0.23 10.26 6.00 31.9 26.9 site5 FALSE FALSE FALSE 29.8 183 0.43 11.34 7.58 16.88 24.8 25.0 23.6 The auk function format_unmarked_occu() takes care of the reformatting for you. In this function, site_covs are the names of the site-level covariates and obs_covs are the names of the observation-level covariates. Prior knowledge of Wood Thrush, as well as the predictor importance results from the encounter rate lesson, inform what land cover variables we choose as occupancy covariates. The five effort variables should always be included as detection covariates, but we’ll also examine whether different habitat types affect the detection probability. # format for unmarked, select occupancy and detection covariates occ_wide &lt;- format_unmarked_occu(occ, site_id = &quot;site&quot;, response = &quot;species_observed&quot;, site_covs = c(&quot;latitude&quot;, &quot;longitude&quot;, # % deciduous forest &quot;pland_04&quot;, # % mixed forest &quot;pland_05&quot;, # % cropland &quot;pland_12&quot;, # % urban &quot;pland_13&quot;), obs_covs = c(&quot;time_observations_started&quot;, &quot;duration_minutes&quot;, &quot;effort_distance_km&quot;, &quot;number_observers&quot;, &quot;protocol_type&quot;, &quot;pland_04&quot;, &quot;pland_05&quot;)) Exercise Explore both the occ_wide and occ data frames. They contain the same data in different formats. Try to understand how one data frame was transformed into the other. As described in lesson 7, we’ll use spatial subsampling to reduce spatial bias. However, here we’ll subsample at the level of ‘sites’ rather than observations. # generate hexagonal grid with ~ 5 km betweeen cells dggs &lt;- dgconstruct(spacing = 5) # get hexagonal cell id for each site occ_wide_cell &lt;- occ_wide %&gt;% mutate(cell = dgGEO_to_SEQNUM(dggs, longitude, latitude)$seqnum) # sample one checklist per grid cell occ_ss &lt;- occ_wide_cell %&gt;% group_by(cell) %&gt;% sample_n(size = 1) %&gt;% ungroup() %&gt;% select(-cell) Finally, we’ll convert this data frame of observations into an unmarked object in order to fit occupancy models. # creat unmarked object occ_um &lt;- formatWide(occ_ss, type = &quot;unmarkedFrameOccu&quot;) 11.2 Occupancy modeling Now that the data are prepared, we can fit a single-season occupancy model to using the occu() function, specifying the detection and occupancy covariates, respectively, via a double right-hand sided formula of the form ~ detection covariates ~ occupancy covariates. # fit model occ_model &lt;- occu(~ time_observations_started + duration_minutes + effort_distance_km + number_observers + protocol_type + pland_04 + pland_05 ~ pland_04 + pland_05 + pland_12 + pland_13, data = occ_um) # look at the regression coefficients from the model summary(occ_model) #&gt; #&gt; Call: #&gt; occu(formula = ~time_observations_started + duration_minutes + #&gt; effort_distance_km + number_observers + protocol_type + pland_04 + #&gt; pland_05 ~ pland_04 + pland_05 + pland_12 + pland_13, data = occ_um) #&gt; #&gt; Occupancy (logit-scale): #&gt; Estimate SE z P(&gt;|z|) #&gt; (Intercept) -1.930 0.239 -8.09 5.98e-16 #&gt; pland_04 7.698 2.342 3.29 1.01e-03 #&gt; pland_05 0.925 0.793 1.17 2.43e-01 #&gt; pland_12 -1.088 1.907 -0.57 5.68e-01 #&gt; pland_13 -2.179 1.006 -2.17 3.02e-02 #&gt; #&gt; Detection (logit-scale): #&gt; Estimate SE z P(&gt;|z|) #&gt; (Intercept) -1.48021 0.60437 -2.449 0.01432 #&gt; time_observations_started -0.03619 0.02915 -1.242 0.21437 #&gt; duration_minutes 0.00113 0.00339 0.332 0.73982 #&gt; effort_distance_km 0.07467 0.15358 0.486 0.62684 #&gt; number_observers 0.48063 0.33169 1.449 0.14733 #&gt; protocol_typeTraveling 0.88882 0.37258 2.386 0.01705 #&gt; pland_04 -0.73640 0.53583 -1.374 0.16934 #&gt; pland_05 3.25239 1.06567 3.052 0.00227 #&gt; #&gt; AIC: 690 #&gt; Number of sites: 575 #&gt; optim convergence code: 0 #&gt; optim iterations: 61 #&gt; Bootstrap iterations: 0 11.2.1 Assessment The MacKenzie and Bailey [-@mackenzieAssessingFitSiteoccupancy2004] goodness-of-fit test can be used to assess the occupancy model fit. Note that to produce accurate results, this process requires simulating about 1,000 bootstrap samples, which can take a long time to run. For the sake of speed, if you want to run the below code, we suggest using nsim = 5. occ_gof &lt;- mb.gof.test(occ_model, nsim = 1000, plot.hist = FALSE) print(occ_gof) #&gt; #&gt; MacKenzie and Bailey goodness-of-fit for single-season occupancy model #&gt; #&gt; Chi-square statistic = 1630 #&gt; Number of bootstrap samples = 1000 #&gt; P-value = 0.593 #&gt; #&gt; Quantiles of bootstrapped statistics: #&gt; 0% 25% 50% 75% 100% #&gt; 571 1385 1755 2195 14050 #&gt; #&gt; Estimate of c-hat = 0.83 11.3 Prediction Now we can estimate the distribution of Wood Thrush in BCR 27 and produce a map. Recall that when we predicted encouter rate, we had to include effort variables in our prediction surface. We don’t need to do that here because the estimated occupancy doesn’t depend on the effort covariates, these only occur in the detection submodel. In addition, predict() can produce both predictions as well as estimates of the standard error. # make prediction for bcr 27 occ_pred &lt;- predict(occ_model, newdata = as.data.frame(pred_surface), type = &quot;state&quot;) # add to prediction surface pred_occ &lt;- bind_cols(pred_surface, occ_prob = occ_pred$Predicted, occ_se = occ_pred$SE) %&gt;% select(latitude, longitude, occ_prob, occ_se) Checkpoint Predicting on the full prediction surface will typically take several minutes. As the above code runs, let’s take a short break. Next, we want to plot these predictions. We’ll convert this data frame to spatial features using sf, then rasterize the points using the prediction surface raster template. r_pred &lt;- pred_occ %&gt;% # convert to spatial features st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) %&gt;% st_transform(crs = projection(r)) %&gt;% # rasterize rasterize(r) r_pred &lt;- r_pred[[c(&quot;occ_prob&quot;, &quot;occ_se&quot;)]] Finally, we can map these predictions! # project predictions r_pred_proj &lt;- projectRaster(r_pred, crs = map_proj$proj4string, method = &quot;ngb&quot;) par(mfrow = c(2, 1)) for (nm in names(r_pred)) { r_plot &lt;- r_pred_proj[[nm]] par(mar = c(3.5, 0.25, 0.25, 0.25)) # set up plot area plot(bcr, col = NA, border = NA) plot(ne_land, col = &quot;#dddddd&quot;, border = &quot;#888888&quot;, lwd = 0.5, add = TRUE) # occupancy probability or standard error if (nm == &quot;occ_prob&quot;) { title &lt;- &quot;Wood Thrush Occupancy Probability&quot; brks &lt;- seq(0, 1, length.out = 21) lbl_brks &lt;- seq(0, 1, length.out = 11) %&gt;% round(2) } else { title &lt;- &quot;Wood Thrush Occupancy Uncertainty (SE)&quot; mx &lt;- ceiling(1000 * cellStats(r_plot, max)) / 1000 brks &lt;- seq(0, mx, length.out = 21) lbl_brks &lt;- seq(0, mx, length.out = 11) %&gt;% round(2) } pal &lt;- abundance_palette(length(brks) - 1) plot(r_plot, col = pal, breaks = brks, maxpixels = ncell(r_plot), legend = FALSE, add = TRUE) # borders plot(bcr, border = &quot;#000000&quot;, col = NA, lwd = 1, add = TRUE) plot(ne_state_lines, col = &quot;#ffffff&quot;, lwd = 0.75, add = TRUE) plot(ne_country_lines, col = &quot;#ffffff&quot;, lwd = 1.5, add = TRUE) box() # legend par(new = TRUE, mar = c(0, 0, 0, 0)) image.plot(zlim = range(brks), legend.only = TRUE, breaks = brks, col = pal, smallplot = c(0.25, 0.75, 0.06, 0.09), horizontal = TRUE, axis.args = list(at = lbl_brks, labels = lbl_brks, fg = &quot;black&quot;, col.axis = &quot;black&quot;, cex.axis = 0.75, lwd.ticks = 0.5, padj = -1.5), legend.args = list(text = title, side = 3, col = &quot;black&quot;, cex = 1, line = 0)) } 11.4 Exercises Now that you’ve completed this lesson, try modifying your script to complete at least one of the following exercises: Try sampling more than a single checklist per grid cell in the spatiotemporal sampling. How does that affect model fit and predictions? What happens to the size of dataset if you only use stationary counts, or reduce the distance traveled to 1 km? How does it impact the results? How does the different input data affect your interpretation of the results? What happens to the size of the dataset if you allow repeat visits to be by multiple observers? How does this impact the results. Produce a map based on model averaged predictions. Note that making these predictions may take up to an hour. "]
]
